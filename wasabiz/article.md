<!-- 高速SATソルバーを支える技術 -->

# はじめに

yabaitech.tokyo vol.6 をご覧の皆さんおはようございます。wasabiz です。
これまでの yabaitech.tokyo では定理証明支援系を自作したり(vol.2)、粘菌を愛でたりして(vol.3)計算の本質に迫る試みを行ってきました。言い換えるとこれまでは「どういった問題が計算機で解けるのか」に注目していたわけですが、第六回となる今回は少し趣向を変えて「どうやって *速く* 問題を解くか」に注目したいと思います。具体的には、本記事では「速いSATソルバー」を作る方法について解説していきます。

## 実装について

この記事で紹介するコードは全て以下のリポジトリにまとまっています。
https://github.com/nyuichi/yabai-sat
節ごとの内容が1コミットに対応しており、各コミットの差分も必要最低限になるように注意深く書かれています。(めっちゃ歴史修正頑張りました。)
この記事ではコードの全体像を追うことはせず核となるアルゴリズムの部分の解説しか行っていないので、実際に動くコードを確認しながら理解したい・記事に書かれていない細かい部分が分からなくて混乱するという場合にはぜひ上記リンク先と照らし合わせながら読み進めてみてください。

## NP完全問題とSATソルバー

SATソルバーと聞くと、大半の人は「NP完全問題とかいう問題を解くソルバーらしい」というぐらいの感想が思い浮かぶのではないでしょうか。この言明自体は間違っていないのですが、これが意味することがなんなのかを正確に理解するためにはNP完全問題とは何かを知る必要があります。ではNP完全問題とはなんなのでしょうか。

NP完全問題とは何かを説明するためにはまず計算量理論の基本的な概念であるPやNPといったクラスについての理解が必要になります。Pとは多項式時間で解くことができる判定問題のクラスです。オーダーの記法を使えば入力のサイズ`n`に対して`O(1)`、`O(n)`、`O(n^3)`、`O(nlogn)`などの時間で判定できる問題はいずれもPに属します。Pに属する問題は計算量理論においては「最も基本的」で「簡単な」問題だと考えられてます。ただしこれは実用上簡単に解けると言う意味ではなく、例えば`O(n^10000)`のように指数の肩が大きい計算量であってもPに属する問題です。このような問題を簡単と言われてしまうとやや驚きますが、世の中にはこれらより遥かに難しい問題がたくさんあるのでそれらより相対的に難しいと言う意味で簡単であるとみなされています。

Pにさらに難しい問題を付け加えたクラスの一つがNPです。NPとは判定問題の答えがyesであることの「証拠」が与えられたときにその証拠が正しいかを多項式時間で判定できる問題のクラスです。少しややこしいですが、平易に言い換えれば「自力で正解を見つけるのは難しい(かもしれない)が、ある答案が正しいか間違っているかは簡単にわかる」ような問題のクラスです。例えばぷよぷよに関する以下の問題はNPだそうです(実はNP完全)。[松金&武永 05]

> 縦と横に十分広いぷよぷよを考える。ぷよの初期配置$B$とこれから降ってくるぷよの列$P$、自然数$k$が与えられたとき、このぷよぷよをプレイして$k$連鎖できるか？

この問題における「証拠」はぷよの操作の列です。操作の列が与えられれば実際にそれをプレイしてみるだけで本当に$k$連鎖できるかどうかがすぐわかります。

ここでP、NPいずれの場合も正式な定義はチューリング機械を用いることに注意してください。通常の直観ではついランダムアクセスメモリやランダムアクセスストレージがついた普通の計算機で考えてしまいますがそれは不正確です。入力のサイズもビット数を表します。今あげたぷよぷよの問題がNP問題であるという定理も、証明を全て展開すれば最終的にはチューリングマシン上でぷよぷよを実行しています。

数あるNP問題の中でも普遍的なものをNP完全問題といいます。どういうことかというと、「それさえ解ければ他のどんなNP問題も簡単に解ける」ようなNP問題をNP完全であると呼ぶという意味です。(正式にはNPに属していてかつ、任意のNP問題を多項式帰着できるような問題のことです。)つまり、何らかのNP完全問題とそのソルバーがあればあらゆるNP問題が「簡単に」解けることになります。そしてそのような問題の一つがCNF-SATです。

CNF-SAT (より短くSAT) は以下のような問題です。いくつか単語を定義します。

- 真($\top$)か偽($\bot$)かのどちらかが割り当てられる変数を論理変数と言う。
- 論理変数($V$)か論理変数に否定をつけたもの($\neg X$)をリテラルと言う。
- 0個以上のリテラルを有限個「または」で繋いだものを節と呼ぶ。(例: $(V_1 \lor \lnot V_2 \lor V_3)$)
- 0個以上の節を有限個「かつ」で繋いだものをCNFと呼ぶ。(例: $(V_1 \lor \lnot V_2) \land (\lnot V_1 \lor V_3 \lor V_4)$)

SATとはCNFが一つ与えられた時に、各論理変数に真か偽の割り当てることによってCNF全体を真にする(充足する)ことができるか？という問題です。

> CNF $\Delta$ が与えられたとき、$\Delta$を充足させる割り当ては存在するか？

非常に有名な事実としてSATはNP完全問題です。よって、SATの高速なソルバーを作ることであらゆるNP問題を高速に解くための手段が得られることになります。

## SATソルバーを作ろう！

解くべき問題が明らかになったところで、さっそく実際にSATソルバーを作っていくことにしましょう！

この記事の残りの部分ではSATソルバーを高速化する際に必要な要素技術について順を追って解説していきます。現代の高速な(いわゆるstate-of-the-artの)SATソルバーというのは一朝一夕で出てきた突拍子もない技術によって成り立っているわけではありません。古くは1960年ごろから続く地道な改良によって成り立っています。この記事ではその歴史に倣い、ナイーブなアルゴリズムを徐々に改良していくことで現代的なSATソルバーを構築していきます。

SATソルバーの高速化については毎年たくさんの論文が出ており、多くのテクニックが提案されています。この記事ではそれらの中でも概ね評価が安定し、実績があり、理論的にも性能向上が保障され、多くのソルバーで採用されているような技術に絞って解説を行います。各技術は独立性が高いのでそれぞれだけを実装することも可能ですが、解説の都合上、他の技術を実装済みのコードベースの上にさらに新しい技術を実装していく流れにしています。これから解説する各技術の間の依存関係は以下の通りです。

![名称未設定のノート-8.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/11779/e73dfab1-e328-13a3-e7af-56ddcd5f07bd.jpeg)

解説に移る前に一点コメントを残しておきます。この記事で紹介するのはいわゆる _系統的ソルバー (systematic solver)_ と呼ばれるものです。このタイプのソルバーは入力のCNFが充足可能であればその割り当てを返し、充足不能(充足する割り当てが存在しない)であればその事実を報告します。他にも _確率的ソルバー (stochastic solver)_ と呼ばれるタイプのソルバーも存在します。このタイプのソルバーは確率的な探索を行うため問題が充足可能な場合にはその割り当てを返すことはできますが、充足不能だった場合にはそれを判定することができません。確率的ソルバーも近年は研究が進み高速なものが登場しているようですが、今回の記事ではそれらについては全く扱いません。ただし、近頃は系統的ソルバーに確率的ソルバーの技術を取り入れたソルバーも登場してきているそうなので、系統的ソルバーを究極まで高速化するためには確率的ソルバーの技術を避けては通れないでしょう。

# ナイーブなアルゴリズム

最も簡単なSATソルバーのつくり方は全探索です。与えられるCNFの大きさが有限なので論理変数への真偽の割り当てを全通り調べる方法で解を求めることができます。この方法では変数の数$n$に対して$2^n$回の反復が必要になってしまうので、例えば100変数の問題を解くのは絶望的です。

これは全探索というアルゴリズムが悪いのではなく、NP完全問題自体がそもそも最悪ケースでは絶対にこれぐらいの計算量がかかってしまうものなのが原因です。残念ながら、理論的な観点から言えばこの指数アルゴリズムを改良するような手法は存在しません。(もしP=NPとかだったりするとまた別です。)

しかし、これはあくまで最悪ケースの話です。現実的な入力の場合はほとんどの場合最悪ケースとは違って、$2^n$の広さの探索空間全てを探索することなく充足可能性を判定することができます。

例えば、CNFの中に一つのリテラルだけからなる節を見つけることができれば、それだけで探索空間が半分になります。以下のCNFは解を持つとすればその解の変数$V_1$の割り当ては必ず偽になるはずです。(そうでないと2個目の節が充足されない。)そのため$2^n$個の割り当てのうち$V_1$を真とするような$2^{n-1}$個の割り当ては調べる必要がないということがすぐにわかります。

$$
(V_1 \lor \lnot V_2) \land (\lnot V_1) \land (\lnot V_2 \lor V_3 \lor \lnot V_4)
$$

あるいは、入力のCNFの全ての節が高々二つのリテラルで構成されている場合その問題は入力に対して線形時間で解くことができます。(そのような問題を2SATと呼びます。)

このようにして、$2^n$個の解の候補のうち絶対に解にならない割り当てを探索する前に判断する(つまり枝刈りする)ことで、非常に大きな問題であっても現実的な入力であれば(典型的には)高速に解くことができます。以降の節では、そのような最適化を少しずつ実装していきます。

# バックトラック

ここでは最も基本的な最適化であるバックトラックを実装します。今バックトラックを「最も基本的な最適化」と表現しましたが、これは少し不思議な表現です。一般的には「バックトラック」と言う単語は単なる反復の実装方法を指すからです。本当のことをいうと、今から実装するバックトラックは通常の意味のバックトラックの上にある種の枝刈りを実装したものです。その具体的な枝刈りとは「割り当てを途中まで決めた段階で矛盾が見つかったら、その割り当てをやめて次の割り当てを探索する」と言うものです。

例えば $(L_1 \lor L_2) \land (L_3 \lor L_4)$ と言う問題を考えます。($L_1$から$L_4$は何らかのリテラルを表しています。)ここでバックトラック中に $L_1$ と $L_2$ に共に偽が割り当てられ $L_3$ と $L_4$ は未割り当てだったとしましょう。(リテラル$L$を割り当てる、というのはここでは$L$を真にするように変数を割り当てる、ということです。例えば$L=\lnot V$なら、$V$に偽を割り当てることを指します。)この時点で一つ目の節である $(L_1 \lor L_2)$ が偽に評価されるので $L_3$ と $L_4$ の割り当てを決めずとも今の割り当てでは解が見つからないことがわかります。そこで全ての割り当てを決める前に現在の探索空間を捨てて他の空間  ($L_1$と$L_2$に対する他の割り当て) に移る、というのが今回実装する枝刈りです。

この節で紹介するソルバーはアルゴリズムとしては以上で終わりです。つまり、単なるバックトラックに単純な枝刈りを加える以外は何もしません。

この方法がうまくいくためには反復のたびに矛盾を見つけるコストよりもそれによって探索空間を削減できるメリットの方が大きい必要があります。これについてはもちろん問題にもよるのですが、実際に動かしてみると**極めて良い性能を示します**。この節では矛盾を見つける処理を非常にナイーブに実装しますが、そのような実装であってもなお非常に高速にしてくれます。

さて、アルゴリズムについてはこれで終わりですが、この節のもう一つのポイントは実装テクニックです。この節で紹介するソルバーの実装はかなり最適化されており、実装テクニックだけでもいくつものアイデアが詰め込まれています。また、コード全体の構造は記事全体を通してほとんど変わらず、性能評価の点でもここでの実装は今後の全ての最適化のベースラインとなるものです。これから記事を読み進めていくにはまずはこの節を理解しておくことが必要でしょう。

## 実装

それでは具体的なコードを見ていきます。
まず先に、大まかな構造を把握するため探索のメインループを見ます。

探索の本体は以下のコードです。

```c++
while (1) {
    while (find_conflict()) {
        if (decision_level == 0)
            return false;
        backtrack();
    }
    if (! decide())
        return true;
}
```

ソルバーはメインループの一番初めに`find_conflict()`を呼んでいますが、これはソルバーの入力として与えられたCNFの中に _空節 (empty clause)_ があるかどうかを調べる関数です。ただしここで空節と呼んでいるものは「現在の割り当ての下で全てのリテラルが偽に評価される節」のことです。節が空ではないのに空節と呼ぶのは変な気がしますが、これは数学的には全てのリテラルが偽に評価される節と空節が同じだとみなされるからです。例えば$V_1=\bot,V_2=\top,V_3=\bot$という割り当ての下では$(V_1 \lor \lnot V_2 \lor V_3)$という節は$(\bot \lor \lnot \top \lor \bot)$と同じであり、節の評価が偽になります。一方で空節$()$も同じく評価が偽になるため、この二つは同一視されます。

ところで、空節というのは残る未割り当ての変数にどのような割り当てを行っても絶対に充足できない節です。そのため、探索中に見つけた空節を「今探索中の割り当てが正しくない割り当てだった」という意味で _矛盾 (conflict)_ と呼ぶことがあります。

メインループの話題に戻りましょう。`find_conflict()`の呼び出しで空節が見つからなかった場合の処理は簡単で、そのまま未割り当ての変数から新たに適当なものを選んで適当な割り当てを行ない(`decide()`)、探索を続けます。このように任意に新たな割り当てを一つ選ぶ操作を _決定 (decision)_ と言います。

さて、問題は`find_conflict()`で空節が見つかった場合です。空節が見つかったということは現在の割り当てが問題の解になっていない/なり得ないということを意味します。もしなんらかの決定を経て今の割り当てに至っている場合はその決定が間違っていたということになります。その場合は、一番最後に行った決定まで探索を巻き戻して他の選択肢を試します。(`backtrack()`) あとで再度解説しますが、このSATソルバーの`backtrack()`は他の選択肢を試す際に、最後の決定の割り当ての真偽を単に反転させます。

具体例で考えてみます。一回目の決定で$V_1=\top$, 二回目の決定で$V_2=\top$を割り当て、三回目の決定で$V_3=\top$を割り当てたところ空節が見つかったとしましょう。ここで空節が見つかったということは$V_1=\top$かつ$V_2=\top$ならば$V_3=\bot$でなければならないということを意味します。そこで、この実装では$V_3=\top$という決定を巻き戻し、真偽を反転させて$V_3=\bot$を割り当てます。

この例での最後の割り当て($V_3=\bot$)はそれ以前の二回の決定($V_1$と$V_2$への割り当て)から導かれる論理的帰結だったことに注目してください。つまり$V_3=\bot$という割り当ては決定による割り当て(ソルバーが好きに選んだ割り当て)ではなく他の割り当てからの含意による割り当てであると言えます。このように、変数の割り当ては「決定によって割り当てられたもの」と「含意によって割り当てられたもの」の二種類に分類することができます。

この二種類の区別は非常に重要なので、後々のために言葉を整理します。変数$V$が割り当て済みだとします。その割り当てが決定による割り当ての時、その変数を _決定変数 (decided variable)_ と言い、そうでない場合(つまり、他から論理的に導かれた場合)その変数を _含意変数 (implied variable)_ と言います。また、$V$が決定変数の時、その割り当て自体を _決定 (decision)_ と呼び、$V$が含意変数の時、その割り当て自体を _含意 (implication)_ と呼びます。同様に、リテラル$L$が割り当て済み(つまり$L$を構成する変数$V$が割り当て済み)でかつ$L$が真に評価される時、$V$が決定変数なら$L$を _決定リテラル (decided literal)_と呼び、$V$が含意変数なら$L$を _含意リテラル (implied literal)_ と呼びます。

決定と含意の区別は「決定レベル」という言葉を用いるとさらにわかりやすくなります。探索中のある時点において、その時の決定変数の数を _決定レベル (decision level)_ と呼びます。また、割り当て済みの変数$V$について、$V$の割り当てが得られた時の決定レベルを$V$の決定レベルと呼びます。例えば、初めての決定によって$V=\top$が割り当てられた場合、$V$の決定レベルは$1$です。($0$ではないのがポイント。)

先程の例を決定レベルを用いて図示すると以下のようになります。決定レベル$1$で$V_1=\top$が、決定レベル$2$で$V_2=\top$が決定され、その含意として$V_3=\bot$が割り当てられています。(変数$V_3$に偽を割り当てることはリテラル$\lnot V_3$を割り当てることと同じ(というか「リテラルを割り当てる」の意味をそう定義した)なので、図ではリテラルを書いて割り当てを表現しています。)

![名称未設定のノート-3 4.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/11779/e4d9725c-b369-91c8-e765-9ce97a2e5a9a.jpeg)

これは小さな例を図示しましたが、一般的には一つの決定が複数の含意を導くことがあります。例えば、以下の場合では$V_1$から$V_7$までの割り当てによって$V_8$が含意されていることを意味します。加えて、図にあるように決定レベル$0$の含意が生まれる可能性もあります。例えば極端なケースとして、与えられたCNFの中に$(\lnot V_1)$という節が存在すれば、ソルバーが決定が一切行わない状態でも論理的帰結として$V_1=\bot$が得られます。

![名称未設定のノート-3 3.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/11779/479b2a15-f8d2-e4f8-d7f4-31ee80f2eedd.jpeg)

このように、探索が進み空節が導かれるに従って含意による割り当てがどんどん増えていき、それによりさらに空節が見つかりやすくなる、ということが繰り返されていきます。そして、割り当て方が1通りしかあり得なくなった変数は決定レベル$0$の含意として登録されていきます。決定レベル$0$の含意が増えていけばそれにより空節が見つかる可能性も増えていきます。そして、もし決定レベル$0$の含意だけから空節が導かれた場合、それはもう他の選択肢がない、つまり問題自体が充足不能であった、ということを意味します。

大まかな構造を説明したところでより細かい部分に焦点を当てていきます。

まずは必要なデータ構造についてです。

変数は1からNまでの数字で表されています。0は変数を表しません。リテラルは変数に符号をつけたもので、ここでは否定がついたリテラルを負数で表しています。一般に、$L$をリテラルとした時$L$の_補リテラル (complement)_ $\overline L$は以下で定義されます。
$$
\overline L =
\begin{cases}
\lnot V & (L = V) \\\
V & (L = \lnot V)
\end{cases}
$$
コード上で`lit`の補リテラルを得るには単に`-lit`とします。

ソルバーのソースコードの先頭には`N`、`M`、`F`というグローバル変数が用意されていて、`N`が変数の数、`M`が節の数、`F`が問題を表すCNFです。(formulaの頭文字のつもり。) これらは一度初期化された後は変更されることはありません。このように、ソルバー全体を通してグローバル変数を多用しています。(いわゆる競プロ的なコード。)

ちなみに、`uint`は`unsigned`のことです。後で`uchar`というのも出てきますが`unsigned char`のことです。

```c++
uint N; // number of variables
uint M; // number of initial clauses
vector<vector<int>> F; // problem
```

SATソルバーの実装方針には、新たな割り当てが発生するたびにCNFをどんどん書き換えていく方法と、CNFを固定したまま割り当ての情報だけを更新していく方法の二種類があります。教科書的な方法は前者ですが、速度を求める場合は後者を採用します。よって今回も後者の方法で実装します。今回作ったソースコードでは`model`というグローバル変数が現在の割り当てを表します。`model`は長さが`N+1`のベクタで、各要素はビットフラグになっています。(0番目の要素`model[0]`は使われません。)そのフラグの内容は`MODEL_DEFINED`がその変数が割り当て済みであることを表していて、`MODEL_PHASE`は変数が割り当て済みであるときに真が割り当てられていることを表します。

`defined`と`phase`は`model`から変数の状態を取り出す関数です。関数`ev`は今の割り当てによって変数がどう評価されるかをリテラルの形で返します。変数`v`に真に割り当てられていれば`ev(v)`は`v`に、偽に割り当てられていれば`-v`に、未割り当てなら`0`になります。こうするとリテラル`lit`について`ev(abs(lit)) == lit`と書くことで`lit`が真に評価されるかどうかを確認できるようになるので便利です。(他のソルバーでこのやり方を採用しているのをみたことがないのですがめっちゃ便利なのでもっと広まればいいなと思ってます。)

```c++
enum {
    MODEL_DEFINED = 1,
    MODEL_PHASE = 2,
};
vector<uchar> model;

bool defined(uint var) {
    return (model[var] & MODEL_DEFINED) != 0;
}
bool phase(uint var) {
    return (model[var] & MODEL_PHASE) != 0;
}
int ev(uint var) {
    return ! defined(var) ? 0 : phase(var) ? (int) var : -(int) var;
}
```

探索に使うデータは以下の通りです。バックトラックの過程でどう言う経路を辿ってきたかを`trail`というスタックに格納しています。`trail`は先程の決定レベルの図の中のリテラルを一列に並べたものだと思ってください。なので、割り当てを行うたびに伸び、バックトラックで割り当てを未割り当てに戻すたびに縮みます。`decision_level`は現在の決定レベルを表します。

`push()`と`pop()`はそれぞれ割り当てを行なったり、割り当てを巻き戻すための関数です。それぞれ`trail`を伸ばしたり縮めたりします。

`push(lit)`はリテラル`lit`を割り当てます。(解説パートですでにちらっと言いましたが、「リテラル$L$を割り当てる」というのは$L$が真に評価されるように変数の割り当てを行うという意味です。)例えば`push(-42)`を実行すると変数`42`に偽が割り当てられます。`pop()`は一回呼ばれるごとに一番最後の割り当てを一つ巻き戻します。

バックトラックを行うときは`pop()`を呼び出して割り当てを巻き戻すことを繰り返します。このとき直近の決定までたどり着いたら処理を終了する必要があります。これを実現するため、`trail`の中のどれが決定だったかを判定できるように決定を行うたびに`trail`には`0`を積むことにしています。(すぐ後に出てくる`decide()`と`backtrack()`の実装を参照。)なので、`trail`のなかの`0`の数と`decision_level`は一致します。

```c++
vector<int> trail; // 0 for decision mark
int decision_level;

void push(int lit) {
    uint var = abs(lit);
    model[var] = lit > 0 ? MODEL_DEFINED | MODEL_PHASE : MODEL_DEFINED;
    trail.push_back(lit);
}
int pop() {
    int lit = trail.back();
    uint var = abs(lit);
    model[var] &= ~MODEL_DEFINED;
    trail.pop_back();
    return lit;
}
```

空節を探す`find_conflict()`は単に全ての節についてループを回しています。ここは特に面白いことはありません。

```c++
bool find_conflict() {
    for (auto & c : F) {
        int num_undef = 0;
        for (auto lit : c) {
            if (! defined(abs(lit))) {
                ++num_undef;
            } else if (ev(abs(lit)) == lit) {
                goto next;
            }
        }
        if (num_undef == 0)
            return true; // conflict found
    next:;
    }
    return false; // no conflict found
}
```

`backtrack()`は先程の解説通りに実装されています。直近の決定まで`trail`を巻き戻したあと、割り当ての真偽値を反転させています。一番最後の`push()`は含意のため、決定レベルは増加されません。

```c++
void backtrack() {
    int lit = 0;
    for (uint i = trail.size() - 1; trail[i] != 0; --i)
        lit = pop();
    trail.pop_back(); // remove the mark
    --decision_level;
    push(-lit); // flip the decision
}
```

決定をおこなう`decide()`もここまでの解説を読めば特に難しくはないでしょう。適当な変数とその真偽を選び(`choose()`)、`trail`に決定を行なったことを記録します。決定を行う際は`trail`に`0`を積んでそれを記録し、決定レベルを一つ増やします。もし選ぶべき変数がなければ、現在の割り当てが解になっているということを意味します。この段階では変数選択(`choose()`)は非常にナイーブな実装になっていて、線形に未割り当ての変数を探索した上で真と偽のうち常に真を選ぶようになっています。もし真の割り当てが間違っていたことがわかるとバックトラックの中で決定をひっくり返して再度探索が行われるのでそのうち偽の割り当ても試されることになります。

```c++
int choose() {
    for (uint v = 1; v <= N; ++v) {
        if (! defined(v))
            return (int) v;
    }
    return 0;
}

int decide() {
    int lit;
    if ((lit = choose()) == 0)
        return false; // sat
    trail.push_back(0); // push mark
    ++decision_level;
    push(lit);
    return true;
}
```

コード全体は以下の通りです。実はこの段階でも適当に作ったソルバーと比べて遥かに（本当に遥かに！）速いのですが、これをさらにさまざまなテクニックを使って高速化していきます。

```c++
uint N; // number of variables
uint M; // number of initial clauses
vector<vector<int>> F; // problem

enum {
    MODEL_DEFINED = 1,
    MODEL_PHASE = 2,
};
vector<uchar> model;
vector<int> trail; // 0 for decision mark
uint decision_level;

bool defined(uint var) {
    return (model[var] & MODEL_DEFINED) != 0;
}
bool phase(uint var) {
    return (model[var] & MODEL_PHASE) != 0;
}
int ev(uint var) {
    return ! defined(var) ? 0 : phase(var) ? (int) var : -(int) var;
}

void push(int lit) {
    uint var = abs(lit);
    model[var] = lit > 0 ? MODEL_DEFINED | MODEL_PHASE : MODEL_DEFINED;
    trail.push_back(lit);
}
int pop() {
    int lit = trail.back();
    uint var = abs(lit);
    model[var] &= ~MODEL_DEFINED;
    trail.pop_back();
    return lit;
}

void backtrack() {
    int lit = 0;
    for (uint i = trail.size() - 1; trail[i] != 0; --i)
        lit = pop();
    trail.pop_back(); // remove the mark
    --decision_level;
    push(-lit); // flip the decision
}

bool find_conflict() {
    for (auto & c : F) {
        int num_undef = 0;
        for (auto lit : c) {
            if (! defined(abs(lit))) {
                ++num_undef;
            } else if (ev(abs(lit)) == lit) {
                goto next;
            }
        }
        if (num_undef == 0)
            return true; // conflict found
    next:;
    }
    return false; // no conflict found
}

int choose() {
    for (uint v = 1; v <= N; ++v) {
        if (! defined(v))
            return (int) v;
    }
    return 0;
}

int decide() {
    int lit;
    if ((lit = choose()) == 0)
        return false; // sat
    trail.push_back(0); // push mark
    ++decision_level;
    push(lit);
    return true;
}

bool solve() {
    model.resize(N + 1);
    trail.reserve(2 * N);
    decision_level = 0;

    while (1) {
        while (find_conflict()) {
            if (decision_level == 0)
                return false;
            backtrack();
        }
        if (! decide())
            return true;
    }
}
```

## Boolean Constraint Propagation

記事の冒頭でも言及したように、現代の高速なSATソルバーたちはどれも基本的な構造が同じです。と言うのも、いずれも1960年代に開発されたアルゴリズムをベースに改良を加えていったものだからです。そのアルゴリズムというのが _DPLLアルゴリズム_ と呼ばれるものです。

DPLLアルゴリズムは以下の三つの規則を節集合に対して適用して解を求めるアルゴリズムです。

1. 単位伝搬 (unit propagation) (Boolean Constraint Propagation (BCP))
2. 純リテラル除去 (pure literal elimination)
3. 分割規則 (splitting rule)

このうち2の純リテラル除去は現代的には採用されないことが多いです。(それでもアルゴリズムの完全性は失われません。) そして3は実は先程のバックトラックの節で説明したアルゴリズムと同じものです。残る1がこの節での主題です。

それでは単位伝搬(あるいはBCP)がどのような処理なのかを説明します。とはいっても単位伝搬の考え方は非常に簡単です。単位伝搬ではまず一つのリテラルだけからなる節を見つけます。そのような節を _単位節 (unit clause)_ と呼びます。実装上は、一つのリテラルが未割り当てで残りのリテラルが全て偽に評価されるような節のことだと考えて下さい。(2個以上のリテラルを持つ節を単位節と呼ぶのは不思議な感じもしますが、空節が全てのリテラルが偽に評価される節だったことを思い出せば違和感はないでしょう。) その節が仮に$(V_1)$だったします。この場合、その節を充足させるには$V_1$に真を割り当てるしかありません。一方でその節が$(\lnot V_1)$だったとすると、その節を充足させるには$V_1$に偽を割り当てるしかありません。なのでどちらにしても含意が一つ得られることになります。この観察に基づき、バックトラック中に単位節を見つけ、それを構成する変数の割り当てを確定させると言うことを繰り返せば探索空間が小さくなることがわかります。これが単位伝搬です。

先程の決定レベルを用いた図で言うと、単位伝搬は含意変数の獲得を促進する処理だといえます。単位伝搬がない実装だと、`trail`に含意変数が積まれるためには一度その変数の否定が決定されてそこから矛盾が導かれる必要がありました。一方、単位伝搬があるとその矛盾を導く処理をショートカットして直接新たな含意を獲得することができます。

### 実装

先程のソルバーからの変更点だけを示します。というのも`find_conflict()`が変わるだけで残りの部分は同じだからです。

基本的な構造はこれまでと同じく、単に節全体をループで回して矛盾を探しているのですが、その際同時に単位節を探すように変更しています。単位節が見つかればそれを伝搬させます。単位節を伝搬させたことによりさらに新しい単位節が見つかることがあるので、単位節が見つかるたびに関数全体を再度実行して単位伝搬を繰り返すようにしています。

```c++
bool find_conflict() {
    bool retry;
    do {
        retry = false;
        for (auto & c : F) {
            int num_undef = 0;
            int undef_lit;
            for (auto lit : c) {
                if (! defined(abs(lit))) {
                    ++num_undef;
                    undef_lit = lit;
                } else if (ev(abs(lit)) == lit) {
                    goto next;
                }
            }
            if (num_undef == 0)
                return true; // conflict found
            if (num_undef == 1) {
                push(undef_lit);
                retry = true;
            }
        next:;
        }
    } while (retry);
    return false; // no conflict found
}
```

# Two Watched Literals

ここまで実装してきたようなバックトラック + BCPをベースとしたソルバーをDPLL型のソルバーと呼ぶのですが、この種のソルバーにおいて最も重要な操作が`find_conflict()`です。`find_conflict()`は空節と単位節の発見の両方を担っており、ソルバーの心臓部とも言えます。しかしこの最も重要な部分がまだナイーブなループによる実装になっています。ここをある種の遅延データ構造によって高速化する方法が知られており、_Two Watched Literals (2WL)_などと呼ばれています。日本語では単に_監視リテラル_と呼ぶことが多いようです。(ちなみに空節を見つけることだけに特化した_One Watched Literal (1WL)_という手法もあります。)

2WLの考え方を理解するために`find_conflict()`について思いを馳せてみます。以下では話を簡単にするために全ての節は長さが2以上であるとしましょう。また、一つの節の中に同じ変数は二回現れないものとします。さて、今から最適化しようとしている`find_conflict()`内のループは単位節と空節を探すためのものでした。もし絶対に単位節や空節になり得ない節をこの対象から除くことができれば`find_conflict()`を高速化することができます。そのために以下の事実を使います。

> 節 $C$ が単位節または空節であるためには $C$ は偽でないリテラルを高々一つしか持たないことが必要。

偽でないリテラルとは真に評価されるかあるいは未割り当てのリテラルを意味します。つまり、この主張にある「偽でないリテラルを高々一つしか持たない」節というのは要するに空節か、単位節か、一つのリテラルが真で残り全てが偽であるような節です。なので、この主張が成立するのは自明です。

この事実から、以下のどちらかの条件を満たす節は探索の対象外としても関数の挙動が変わらないことがわかります。

1. (WI-1) 充足されている
2. (WI-2) 偽でないリテラルを少なくとも二つ持つ。

この二つ条件を合わせて _Watching Invariant (WI)_ と呼びます。

実は`find_conflict()`が`false`を返した直後では全ての節がWIを満たします。なぜなら単位節も空節も存在しないからです。つまり、ソルバーのメインループはWIの観点から見れば

1. `find_conflict()`の結果全ての節がWIを満たすようになる。
2. `decide()`で変数を割り当てる。どれかの節のWIが壊れる。
3. `find_conflict()`で全ての節がWIを満たすまで伝搬を行う。
4. `decide()`で変数を割り当てる。どれかの節のWIが壊れる。
5. ...

という構造になっていることがわかります。(「WIが壊れる」と書いた部分では実際にはWIが壊れないこともあります。)ここでは`find_conflict()`が`false`を返す場合のみを考えましたが、`find_conflict()`が`true`を返す場合もほぼ同じで、バックトラックによって最後の決定を巻き戻した瞬間では全ての節がWIを満たしています。その直後に`backtrack()`は最後の決定の真偽を反転させたものを`trail`に積むので、この瞬間にどこかの節のWIが壊れます。(壊れないこともあります。)

先程の議論から、`find_conflict()`はWIが壊れた節だけを探索すれば全ての単位節・空節を探すことができることが分かっているので、「割り当てによってWIが壊れたかもしれない節」だけを調べる方法があれば`find_conflict()`を高速化することができます。

これを実現するために、各リテラルに対して「それが割り当てられた時にWIが壊れるかもしれない節の集合」を紐づけたいです。これを _監視リスト (watch list)_ と言います。ただし、テクニカルというか、歴史的な事情で、リテラル$L$の監視リストというと、リテラル$\overline L$が割り当てられたときにWIが壊れるかもしれない節の集合を指します。リテラル$L$の監視リストを$\mathrm{watchlist}(L)$と書くことにします。

監視リストがまともに使えるためには探索の過程で以下の不変条件が守られている必要があります。

- (I-WLIST) $L$を割り当てた結果WIが壊れるかもしれない節は全て$\mathrm{watchlist}(\overline L)$に入っている

問題はこの不変条件をどのようにして保ち続けるかです。そこで、監視リストの定義を以下のようにします。

1. 各節に対してその中の異なる二つのリテラルを選ぶ。それらを_監視リテラル (watched literal)_ と呼ぶ。節$c$の監視リテラルを$W_0(c), W_1(c)$と書くことにする。
1. 監視リストは次のように定義する: $\mathrm{watchlist}(L) = \\{ c \mid W_0(c) = L \text{ or } W_1(c) = L \\}$

その上で、以下の不変条件を考えます。

- (I-WL) (WI-1)を満たさないが(WI-2)を満たす(つまり充足されていないが異なる二つの偽でないリテラルを持つ)節について、その監視リテラルはどちらも偽でない。

すると、(I-WL)が成り立てば(I-WLIST)が成り立ちます。WIを満たす節$c$がリテラル$L$の割り当てによってWIを満たさなくなったとします。WIを満たさなくなったということは$c$は(WI-1)を満たさないが(WI-2)を満たす節だったということです。すると(I-WL)より$L$の割り当て前の二つの監視リテラルはどちらも偽ではなかったということになります。仮に$L$が$c$の監視リテラルでないとします。この場合$L$の割り当てによって$c$の監視リテラルの値は変わりません。よって$c$は$L$の割り当て後も(WI-2)を満たすはずです。しかし、$L$の割り当てによって$c$がWIを満たさなくなった、つまり、(WI-2)が満たされなくなったことがわかっているので、$\overline L$が$c$の監視リテラルだったということになります。これはつまり、$c \in \mathrm{watchlist}(\overline L)$ということです。

よって、不変条件(I-WLIST)を維持するためには(I-WL)を維持すればいいことがわかりました。そこで次に、リテラル$L$を割り当てた結果(I-WL)が壊れた場合にそれを修正できるかを考えます。$L$の割り当てによって監視リストの状態が変わりうる節は$\mathrm{watchlist}(L)$の中の節か$\mathrm{watchlist}(\overline L)$の節のどちらかです。しかし、$\mathrm{watchlist}(L)$の節の(I-WL)が壊れることはありません。なぜなら監視リテラル$L$が未定義から真に変わってもどちらも「偽でない」ため(I-WL)の条件を満たし続けるからです。なので$\mathrm{watchlist}(\overline L)$だけに注目すれば良いです。$L$を割り当てた後の$\mathrm{watchlist}(\overline L)$の中の節の状態は

1. 空節になったもの
2. 単位節になったもの
3. (WI-1)を満たす、つまり、充足済みのもの (これは$L$の割り当て以前から節が充足済みだったことを意味します)
4. (WI-1)を満たさないが(WI-2)を満たすもの

の4種類のいずれかに分類できます。1、2の場合はWIを満たしていないので自動的に(I-WL)を満たします。よってこの場合は何もしなくて良いです。3の場合もやはり(I-WL)を満たすので何もしなくて良いです。大事なのは4の場合で、この場合には(I-WL)が満たされるように監視リテラルを選び直すという操作を行います。つまり、節の中の他の偽でないリテラル$L'$を見つけ、$\overline L$の代わりにそれを新たな監視リテラルとします。(それに合わせて監視リストも更新します。)

このやり方の素晴らしいところは割り当てを巻き戻すときに特に何もしなくていいことです。上記のアルゴリズムでは4の場合で監視リテラルの選び直しを行なっていますが、監視リテラルを選び直した後の節が(I-WL)を満たしていれば割り当て$L$を巻き戻しても(I-WL)をそのまま満たします。つまり、$L$の割り当てを行う前から$L'$が監視リテラルとして選ばれていたと考えても特に矛盾しないということです。これは割り当て$L$だけに限らず他の割り当てを巻き戻しても同様です。(ただしきちんと割り当てたのと逆の順に巻き戻す必要はあります。$(L_1 \lor L_2)$を$L_2=\top$、$L_1=\bot$の順に割り当てると割り当て前も後も(I-WL)を満たしますが、これを$L2$から巻き戻すと(I-WL)を満たさない節ができてしまいます。)

以上のアイデアを疑似コードに落とすと以下のようになります。

```
let Q be a queue.
function find-conflict(L)
  assign L
  push L into Q
  while Q is not empty
    M := pop from Q
    for each clause c in watch-list(-M)
      if c is satisfied
        continue
      elif all literals are false
        report conflict
      elif only one literal N is unassigned
        assign N
        push N to Q
      else
        make c watch some other non-false literal
```

`find-conflict`が引数としてリテラルを一つとるようになっていますが、これは`find_conflict()`が呼ばれる前に`trail`に積まれたリテラルと同じものだと思って下さい。つまり、`decide()`によって決定されたリテラルか、あるいは`backtrack()`によって真偽が反転されたリテラルです。

単位伝搬の際に同時にキューにリテラルを積み、そのキューを舐めながら(I-WL)を満たすように監視リストを更新していきます。キューに入れているのは単位伝搬によって獲得した割り当てそれぞれについて監視リストを更新する必要があるためです。

この実装だと先ほどの説明の時と違ってリテラル$L$が割り当てられた瞬間には$\mathrm{watchlist}(\overline L)$は更新されず、$L$がキューから取り出されたタイミングで更新されます。そのため、$\mathrm{watchlist}(\overline L)$の更新のタイミングでは$L$以外にも監視リストが未更新の割り当て済みリテラルが複数存在する可能性があります。この場合も特に特別な処理をする必要はなく、伝搬によって獲得した割り当て全てに対して最終的に監視リストが更新できれば(I-WL)は維持されます。

疑似コードではキューを使いましたが、キューにしていることに特に意味はなく、全部の割り当てについて監視リストを舐められれば良いのでここはスタックでも構いません。ただし、`assign N`を行った瞬間に`-N`の監視リストを更新するようなコード(例えば`find-conflict()`を再帰で書く)は難しいでしょう。というのも、条件分岐の最後で監視リストの付け替えを行っているために監視リストのループを回している最中に監視リストの中身が書き変わってしまう(いわゆるiterator invalidationが発生する)からです。

## 実装

監視リストでは長さが1以下の節や同じ変数が複数回が現れる節の扱いが特殊になるため、入力のCNFを前処理する工程を導入してそのような節を事前に排除しておくことにします。具体的には、

1. 入力に空節が含まれていたら充足不能であると報告して終了する
2. 入力に単位節が含まれていたら決定レベル0の含意として`trail`に積み、そこからの単位伝搬も行っておく
3. $V$と$\lnot V$の両方を持つ節はトートロジーなので節ごと除去する
4. 節に同じリテラルが複数回現れる場合は吸収律によりそれらを一つに潰す

という処理をメインループに入る前に行います。(コードは省略)

追加のデータ構造は以下の通りです。

節を表す構造体`clause`を新たに導入しています。`clause`型の値は前処理済みの節です。`lits`の先頭二つが監視リテラルを表します。

`clause`はflexible array memberを使用しています。`clause`に`vector<int>`のフィールドを生やすよりも間接参照が一回減るからです。しかしflexible array memberはC++では非標準の機能で、clangでも本当にサポートされているかとても怪しいです。(しかしコンパイルしても警告は出ない。)もしかするとundefined behaviorを踏んでいる可能性がありますが今ところこれ由来と思われるバグには遭遇していません。

また、`lits`の先頭二つを監視リテラルとするのをやめて、`clause`の中に`lits`の何番目が監視リテラルかを覚えておくフィールドを生やすという手もあります。むしろ自然な発想はこちらで、先頭二つを監視リテラルとするというやり方はややトリッキーなのですが、コード量としてはむしろ今のやり方の方が少なくなって見通しも良くなるのでこうなっています。

`pos_list`と`neg_list`はそれぞれpositive/negativeなリテラルに対してその監視リストを紐づけます。

```c++
struct clause {
    uint num_lit;
    int lits[]; // lits[0] and lits[1] are watched literals
};
vector<vector<clause *>> pos_list, neg_list;
```

`pos_list`と`neg_list`は以下の関数を通して操作されます。リテラル`lit`からそれに紐づいた監視リストを得るには以下の`watch_list(lit)`を実行します。

```c++
auto & watch_list(int lit) {
    return lit > 0 ? pos_list[lit] : neg_list[-lit];
}
```

それでは2WLを用いた`find_conflict()`の実装を見ていきます。基本的な処理は上記のアルゴリズム解説通りなのですが、いくつか細かい点についてコメントしておきます。

まず、この実装では疑似コードにあったキューがなくなっています。代わりに`trail`をそのままキューとして使うようにして効率化を行なっています。(コード中1.)

疑似コードでは`find-conflict()`は引数を一つ受け取るようになっていましたが、その代わりに`trail`の先頭から直接リテラルを取り出しています。`find_conflict()`は`decide()`か`backtrack()`の後の、リテラル一つだけ単位伝搬が始まっていない状態で呼ばれるのでこのようなコードになっています。ただし、メインループの初回の反復では`trail`が空になり得るので、それを防ぐためにメインループの開始直前に、`trail`が空の時に先に一つ決定を行うというコードを入れています。(コードは省略)

コード中2.では伝搬の結果もう片方のリテラルを取り出す際に`lits[0]`と`lits[1]`をスワップする処理が入っています。これにより、割り当てが伝搬してきたリテラルが節の1番目に、もう片方が節の0番目に入ります。

コード中3.ではこの節が充足済みの場合の処理をしています。ここも先程の疑似コードとは微妙に違っているところで、節の全体を眺めて充足済みかどうか判定するのではなく、もう片方の監視リテラルを見て充足済みかを判定しています。これだと充足済みの節を見逃してしまう場合があるのですが、実はこれでも正しく動きます。そもそも充足済みであっても監視リテラルが二つとも偽でなければ充足済みでないケースと同じように扱って問題ありません。問題は、充足済みでかつ監視リテラルを二つとも偽以外にするのが無理なケースです。今、節の監視リテラルが$L_0,L_1$だとして$L_0$が偽になった状態だとすると、2通りの場合があり得て、

1. $L_1$が真 (つまり監視されていないリテラルが全て偽)
2. $L_1$は偽 (つまり監視されていないリテラルのうち一つだけが真で残りが偽)

のどちらかです。1の場合はコード中3.によってすでにハンドルされています。2の場合はそのまま$L_0$が真なリテラルと付け替えられます。この時点で$L_1$への偽の割り当てはまだハンドルされていないはず($L_0$の方が$L_1$より先に割り当てられてキューに積まれた)なので、$L_0$の付け替えが終わった後にキューから$L_1$が取り出され、そのタイミングでやはりコード中3.によってこの節は充足済みであると判定されます。結果的に、この実装では(I-WL)よりほんの少し強い不変条件を維持していることになります。(関連する考察が[Fleury+, 2018]にあります。)

残りの部分(4.,5.,6.)は概ね疑似コードの通りです。

```c++
bool find_conflict() {
    // 1. trail をキューとして使っている
    for (uint prop = trail.size() - 1; prop < trail.size(); ++prop) {
        int lit = trail[prop];
        auto & wlist = watch_list(-lit);
        for (uint i = 0; i < wlist.size(); ++i) {
            auto c = wlist[i];
            // 2. c->lits[1] が必ず偽になるようにする
            if (c->lits[0] == -lit)
                swap(c->lits[0], c->lits[1]);
            int lit = c->lits[0];
            // 3. c は充足済み
            if (ev(abs(lit)) == lit) // satisfied
                continue;
            for (uint k = 2; k < c->num_lit; ++k) {
                int lit = c->lits[k];
                // 4. c は(WI-2)を満たす
                if (ev(abs(lit)) != -lit) { // update watch list
                    watch_list(lit).push_back(c);
                    swap(c->lits[1], c->lits[k]);
                    wlist[i] = wlist.back();
                    wlist.pop_back();
                    --i;
                    goto next;
                }
            }
            // 5. c は空節
            if (defined(abs(lit)))
                return true; // conflict found
            // 6. c は単位節
            push(lit);
        next:;
        }
    }
    return false; // no conflict found
}
```

2WLが実行時間を削減する要因は二つあります。

ひとつは単純に既知の全ての節を舐めるのをやめたことによるものです。これまでの実装では、単位伝搬の際、一つ割り当てを調べるごとに全ての節を舐めて単位節を探していました。一方2WLでは割り当てごとにその監視リストを舐めるという実装です。監視リストは通常は節全体と比べればとても小さいため、ループの反復回数が少なくなります。

もう一つはバックトラックとの相性の良さです。DPLL型のソルバーはバックトラックにより探索を行いますが、特に探索中に同じ割り当てをバックトラックを挟んで繰り返すことがよく発生します。(あるリテラル$L$を割り当てて、空節を発見しバックトラック、その後探索がするんでもう一度$L$の割り当てが発生する、と言う状況です。) 2WLの実装では与えられたリテラルの単位伝搬を計算する際に監視リストを更新しますが、この際監視リテラルを割り当て直すおかげでそのリテラルを監視している節の数が少なくなります。これにより、同じリテラルを再度割り当てた時に一回目と比べて舐める節の数が減ります。
またこれらの要因によって単に処理量が減るだけでなく、単位伝搬の一回の反復の中で触るメモリの範囲も非常に小さくなり、結果的にキャッシュヒット率が向上します。

2WLは非常に優れたテクニックで、まだまだその巧妙さについて語り尽くせていない部分がたくさんあります。とはいえ長くなるのでここではひとまずこれくらいにしておきましょう。

# Non-Chronological Backtracking

ここまででDPLL型のソルバーの心臓である`find_conflict()`関数を高速化してきました。次に紹介するのはどうやって矛盾を高速に見つけるかではなく、矛盾を見つけた後に何を行うか、についてのお話です。

単位伝搬はDPLL型のソルバーにおける最も重要な操作ですが、それがなぜ重要なのかというと「リテラルを決定して、矛盾を導いて、バックトラックする」という一連の操作を「単位伝搬する」という一回の操作でショートカットできるからでした。つまり、無駄なバックトラックを省けるというのがポイントでした。

実は、現状のソルバーにはまだ無駄なバックトラックが発生している場所があります。それは例えば以下のような状況です。

![名称未設定のノート-4.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/11779/c9656268-b742-de4b-8b84-91ed2f2cc937.jpeg)

$$
(\lnot V_3 \lor V_4) \land
(\lnot V_1 \lor \lnot V_4 \lor V_5) \land
(\lnot V_4 \lor V_6) \land
(\lnot V_1 \lor \lnot V_4 \lor V_6) \land
(\lnot V_5 \lor V_7) \land
(\lnot V_6 \lor \lnot V_7)
$$

今、$V_1,V_2,V_3$が決定されていて、$V_4,V_5,V_6,V_7$が単位伝搬によって割り当てられている状態を考えています。$V_4,V_5,V_6,V_7$はどれも決定レベル3の含意変数です。(この四つを横に並べるとごちゃごちゃしてしまうので改行しています。)太い矢印は単位伝搬の流れを表しています。このようなグラフを _含意グラフ (implication graph)_ と呼びます。含意グラフは必ずDAGです。

この状況では、問題の中の$(\lnot V_6 \lor \lnot V_7)$という節が空節になるため矛盾が導かれています。

前節までの実装ではここで$V_3$の決定がよくなかったと判断して、決定レベル2の含意リテラルとして$\lnot V_3$を積んでいました。しかし、この絵をよく見てみると、今回と同じ矛盾を導くためには$V_1$と$V_3$だけがあればいいことに気づきます。つまり、この矛盾は$V_2$の割り当てがどうなっているかに関わらず発生する矛盾だということです。このことから、$\lnot V_3$を決定レベル2ではなく決定レベル1で積んでも良いということがわかります。

このように、矛盾が起こった理由を解析して、可能であれば二つ以上の決定レベルを巻き戻すことによって探索空間を減らすというのが _矛盾解析 (conflict analysis)_ の基本的な考え方です。

SATの世界ではこのようなバックトラックを_Non-Chronological Backtracking (NCB)_と呼びます。日本語だと_非時間順バックトラック_とか訳したりするようです。また、もう少し一般的な文脈だと、探索木を複数段一気に上がる操作のことを(バックトラックと対比して) _バックジャンプ (backjump)_ と呼ぶようです。

NCBが探索空間を削減するのをイメージするために上記の問題が(実はもっと他に節があって)充足不能だったとします。話を簡単にするために変数選択は番号順に行われて、まず真に割り当てられるものとします。絵の状況から始めて「決定レベル1に$V_1,\lnot V_2,\lnot V_3$が積まれている」という割り当てにたどり着くまでのステップ数を考えると、もしNCBがなければ

1. $\lnot V_3$が決定レベル$2$に詰まれる。
2. 矛盾が導かれる。
3. $\lnot V_2$を決定レベル$1$に詰む。
4. $V_3$を決定レベル$2$で決定する。
5. 矛盾が導かれる。
6. $\lnot V_3$を決定レベル$1$に詰む。

という6ステップですが、NCBがあれば

1. $\lnot V_3$を決定レベル$1$に詰む。
2. 矛盾が導かれる。
3. $\lnot V_2$を決定レベル$1$に詰む。

という3ステップで済みます。(実はNCBは後で説明するphase savingと組み合わせないと効果が薄い(か場合によっては逆効果になる)のですが、その話はまた後で…)

ここまでの例では`trail`の現在のレベルには決定と、そこからの単位伝搬による割り当てだけがある状態を考えていました。実際の探索中ではここにNCBによって得られた割り当てが加わります。例えば、上図の状態からNCBを行うと$\lnot V_3$が決定レベル$1$に積まれます。この時の含意グラフは $V_1$から$\lnot V_3$に向かって太い矢印が生えた状態になります。もし$V_3$よりも前に割り当てられたリテラルで$V_1$以外にも矛盾導出に関わるリテラルがあればそこからの矢印も生えます。

![名称未設定のノート-4 3.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/11779/a9939dcd-2f44-e900-f0a6-14adcce4afa3.jpeg)

ただし、これに関して実装上の注意点があります。

実装上は含意グラフのグラフ構造は「各変数にそれを割り当てた節」を紐づけることで保持します。例えば、$V_1$と$\lnot V_2$が割り当てられている時にそこから$\omega = (\lnot V_1 \lor V_2 \lor V_3)$という節による単位伝搬で$V_3$が割り当てられた場合は、$V_3$に$\omega$由来の割り当てであるという情報を記録しておきます。このように、含意変数が割り当てられた理由となる節を _原因節 (reason clause)_ と呼びます。

問題は、バックトラックによって割り当てられた変数には原因節が存在しないということです。もし矛盾を導出するのに寄与した(現在のレベルの)割り当てが単位伝搬によるものか決定によるものだったのなら含意グラフは原因節だけから完全に復元できます。しかし、そうでない場合は含意グラフを復元できず、バックジャンプ先を正しく計算できなくなります。

この問題に対する解決案は二つあります。

一つは、保守的にバックジャンプ先を計算するというものです。もし矛盾に原因節を持たない(現在のレベルの)含意リテラルが関与していた場合はそのリテラルに対して過去割り当てられた全てのリテラルから矢印が生えている、と考えます。結果的に、そのようなケースではNCBは行われず、一つ上の決定レベルに戻る(つまりこれまでのバックトラックと同じ挙動をする)ことになります。

もう一つのやり方は、仮想的な節を生成してしまうことです。先程の例だと、$\lnot V_3$を割り当てるに至った原因は$V_1$だったので、その情報から動的に$(\lnot V_1 \lor \lnot V_3)$という原因節を生成します。この節は入力の問題には存在しなかった節で、あくまで含意グラフを保持するためだけの仮想的な節です。こちらの方法では探索中にmalloc/freeが頻繁に呼ばれることになりますが、そのおかげでバックジャンプ先を正確に計算することができます。

今回は後者の方法を実装します。

## 実装

メインループの本体は以下のようになります。単位伝搬で空節が見つかった場合に今までは`true`を返していましたが、この時にどの節が空節になったかの情報を`optional`型を使って返すようにします。(これを実現するための`find_conflict()`への変更は非常に簡単なのでコードは省略します。) そして、`analyze()`の中でその解析とNCBを行います。

```c++
while (1) {
    while (auto conflict = find_conflict()) { // ココが変わった
        if (decision_level == 0)
            return false;
        analyze(*conflict); // ココが変わった
    }
    if (! decide())
        return true;
}
```

`analyze()`のコードを見る前に幾つか準備をします。

追加するデータ構造のうち本質的なものは以下の二つです。

`reason`は各変数`v`が含意変数だった場合に原因節を保持します。もし`v`が決定変数だった場合には`nullptr`が入ります。変数が未割り当ての場合の値は不定です。`reason`は次の意味で単射的です: 二つの割り当て済み変数`v1,v2`について、`reason[v1] != nullptr && reason[v2] != nullptr`ならば`reason[v1] != reason[v2]`が成り立つ。これは、直観的には、一度原因節になった節は(バックトラックが起こらない限り)他の変数の原因節にはならないということです。

`level`は変数`v`が割り当て済みだった場合にその決定レベルを保持します。こちらも変数が未割り当ての場合は値は不定です。

```c++
vector<clause *> reason; // nullptr for decision
vector<uint> level;
```

他にも`analyze()`の実装上の都合で使用するデータ構造が追加されます。詳細は後述します。

```c++
vector<bool> seen; // only used in `analyze`
vector<int> learnt; // only used in `analyze`
```

`push()`は`level`と`reason`を更新するように変更されていますがそれ以外は一緒です。
`pop()`は動的に生成した原因節が使われなくなったタイミングでそれを開放する処理が追加されています。これを実現するためには`reason[var]`が問題由来の「ちゃんとした節」か矛盾解析由来の「節もどき」かを判定する必要があるため、`clause`に`flags`というフィールドを追加し、`CLAUSE_LEARNT` というフラグを定義しています。(コードは省略。)

```c++
void push(int lit, clause * c) {
    uint var = abs(lit);
    model[var] = lit > 0 ? MODEL_DEFINED | MODEL_PHASE : MODEL_DEFINED;
    level[var] = decision_level; // ココが変わった
    reason[var] = c; // ココが変わった
    trail.push_back(lit);
}
void pop() {
    int lit = trail.back();
    uint var = abs(lit);
    model[var] &= ~MODEL_DEFINED;
    auto c = reason[var];
    if (c && (c->flags & CLAUSE_LEARNT) != 0) {
        free(c);
    }
    trail.pop_back();
}
```

NCBを実現するため、これまで使っていた決定をひとつ分巻き戻す`backtrack()`の代わりに複数個分の決定を巻き戻す`backjump()`を導入します。`backjump()`は`backtrack()`と異なり最後の決定をひっくり返す処理は行いません。(代わりに`analyze()`のなかでそれを行います。)

```c++
void backjump(uint level) {
    while (decision_level != level) {
        for (uint i = trail.size() - 1; trail[i] != 0; --i)
            pop();
        trail.pop_back(); // remove the mark
        --decision_level;
    }
}
```

さて、肝心の`analyze()`関数を見ていきましょう。

先程の解説パートの通りに実装しようとすると、含意グラフを実際に構成して全ての頂点を見て回る処理が必要に思えます。普通ならこういう状況ではキューかスタックかを用意して、頂点を踏むたびにそこからつながる頂点をそこに積むというループを書くことになります。しかし、実際にはそのように明示的に探索用のキュー/スタックを用意する必要はありません。というのも、`trail`が実質的にそのデータ構造の役割を果たしてくれるからです。

`trail`に並ぶリテラルは下から順に推論の時系列通りに並んでいます。つまり、`trail`の中身は含意グラフがトポロジカルソートされたものだと考えることができます。(含意グラフが必ずDAGになっていることが効いています。ちなみにこのトポロジカルソートはレベル順でのソートになっています。これは2WLで`trail`をキューとして利用していたためです。) ただし、ここでの含意グラフはこれまで割り当てられた全てのリテラルからなる巨大なグラフです。実際に矛盾解析の中で興味があるのは矛盾`conflict`から逆向きに辿っていける頂点からなる部分グラフなので、含意グラフ全体の中からうまくそのような部分グラフを抜き出す必要があります。

といってもこれを実装するのは簡単で、`trail`を上から下に向かって積んだ順とは逆順に辿るときに、矛盾に寄与したリテラルに印をつけていくだけです。トポロジカルソートされているおかげで`trail`の上にあるリテラルの原因となった割り当ては必ずそのリテラルより下の位置にあるので、これだけでうまくいきます。

今回グローバル変数として新たに追加した`seen`の用途の一つがこの印をつける操作です。`seen`は長さが`N+1`の`bool`の配列です。`analyze()`関数の呼び出しの前後では必ず`seen`の全ての要素が`false`になっています。`seen`には変数の決定レベルに応じて二つの役割があります。矛盾が発生した時の決定レベルを$l$とします。

1. 決定レベルが$l$であるような変数`v`については、`seen`は今説明した用途に使われます。つまり、`seen[v]`は含意グラフのうち現在の決定レベルの頂点だけからなる部分グラフを表すために使われます。初期状態では`conflict`からたどれる全ての頂点(変数)の`seen`をまず`true`にし(コード中1.)、探索中には`seen`が`false`なリテラルを無視することで、含意グラフのうち適切な部分グラフだけを辿ります。(コード中2-1.)
2. 決定レベルが$l$未満であるような変数`v`については、`seen[v]`は動的に生成する原因節の中に入れるリテラルが重複しないようにする役割を持ちます。

`analyze()`が開始した時点では必ず`seen`の全ての要素が`false`になっている必要があるので、上記二つのケースそれぞれについてどうやって`seen`を初期化するか考えます。

前者の場合は、`trail`を探索する過程で貪欲に初期化を行なっています。(コード中2-2.) `trail`は因果グラフがトポロジカルソートされているので、変数`v`の原因節のリテラルが`trail`の中で変数`v`より下の位置に洗われるようなことは決してありません。そのため、探索のループ内で`seen`を`false`に戻しても問題なく動きます

後者については、学習節の中に現れている変数の`seen`を`false`にすることで対応しています。(コード中3.)後者に該当する変数は全て`learnt`に入れられているので、`learnt`についてループを回すだけで全ての`seen`が`false`に戻ります。

含意グラフの頂点から新たな頂点を辿るところでは2WLの性質をうまく使っています。(コード中2-3.) 2WLの実装のおかげで、割り当て済みの変数`v`について`reason[v] != nullptr`のとき必ず`abs(reason[v]->lits[0]) == v`が成り立ちます。これのおかげで、単位伝搬を逆向きに辿る際に添字を1から始めるだけで自分自身を除外することができます。

矛盾に寄与したリテラルがリストアップできたら、バックジャンプ先を決定します。(コード中4.) もし矛盾解析を行なった結果、矛盾に寄与するリテラルが全て現在のレベルの割り当てだった場合はレベル0にバックジャンプします。

以上が終わると最後に現在の決定をひっくり返したものを割り当てますが、この時に原因節を生成して登録します。(コード中5.)ただし、原因節の長さが$1$の場合は特殊です。原因節の長さが$1$ということは決定レベル$0$へのジャンプが起こっているはずですが、決定レベル$0$に積まれたリテラルの原因を辿ることはないので(なぜなら`analyze()`は必ず決定レベル$1$以上で呼ばれるからです)、その場合は節は生成せずに`nullptr`にしておきます。

```c++
void analyze(clause * conflict) {
    learnt.push_back(0); // reserve learnt[0] for decided literal
    // 1. 含意グラフ全体の中で conflict からたどれる部分だけ seen をセット
    for (uint i = 0; i < conflict->num_lit; ++i) {
        int lit = conflict->lits[i];
        uint v = abs(lit);
        seen[v] = true;
        if (level[v] < decision_level) {
            learnt.push_back(lit);
        }
    }
    int decision;
    // 2. 幅優先探索の本体
    for (uint i = trail.size() - 1; true; --i) {
        int lit = trail[i];
        uint v = abs(lit);
        // 2-1. 矛盾に関与していないリテラルは無視
        if (! seen[v])
            continue;
        // 2-2. seen の初期化はループ内でやっても問題ない
        seen[v] = false;
        auto c = reason[v];
        if (! c) {
            decision = lit;
            break;
        }
        // 2-3. c->lits[0] は lit なので除外
        for (uint i = 1; i < c->num_lit; ++i) {
            int lit = c->lits[i];
            uint v = abs(lit);
            if (seen[v])
                continue;
            seen[v] = true;
            if (level[v] < decision_level) {
                learnt.push_back(lit);
            }
        }
    }
    learnt[0] = -decision;
    // 3. 決定レベルが現在のレベルより小さい変数の seen の初期化
    uint num_lit = learnt.size();
    for (uint i = 1; i < num_lit; ++i)
        seen[abs(learnt[i])] = false;
    // 4. バックジャンプ先の決定
    uint max_lv = 0;
    for (uint i = 1; i < num_lit; ++i)
        max_lv = max(level[abs(learnt[i])], max_lv);
    backjump(max_lv);
    // 5. 原因節の生成
    if (num_lit == 1) {
        push(-decision, nullptr);
        learnt.clear();
        return;
    }
    push(-decision, make_clause(learnt, CLAUSE_LEARNT));
    learnt.clear();
}
```

# Conflict-Driven Clause Learning

NCB では矛盾が発生するたびにそれを解析して動的に原因節を生成していましたが、この節はあくまで含意グラフを保持するためのもので、通常の節とは異なるものでした。特に、生成した原因節を監視の対象にしていないため、`find_conflict()`でこの節が利用されることはありません。実は、この節を単位伝搬や矛盾の発見に利用しても問題がないどころか、うまく利用することで大幅にソルバーの性能を向上させることができます。

ここまでは動的に生成した原因節はあくまで「含意グラフを構成するための部品」だったのですが、これを本当に「節」だと見ることにすると、どういう節だと思えるでしょうか。結論から言うと、そのような節は「元々の問題からの論理的帰結」だと捉えることができます。論理的帰結ということは、その節を問題の節集合に追加しても充足可能性を変えないということです。(解の集合も変えません。)よって、生成した節を「最初から問題にあった」「本当の節」と見なしても特に問題がないです。

このように生成した原因節を本当の節と見なすことを「節を学習する」あるいは「節を獲得する」と言います。そして、学習した節を学習節と言います。矛盾解析によって学習節を獲得する手法を _Conflict-Driven Clause Learning (CDCL)_と言います。

学習節を獲得することがなぜ重要かというと、それが探索空間の削減につながるからです。例えば、以下のような例を考えます。

$$
(\lnot V_1 \lor \lnot V_2 \lor V_5) \land (\lnot V_2 \lor V_4) \land (\lnot V_3 \lor V_4) \land (\lnot V_3 \lor \lnot V_4) \land (\lnot V_5 \lor \lnot V_4)
$$

これをソルバーで回した時の動作を考えます。$V_1,V_2$を順に割り当てた場合を考えます。$V_1$を割り当てても何も伝搬が起こらず、$V_2$を割り当てたときに伝搬が発生して$V_4,V_5$への割り当てが行われます。しかしこれはCNFの最後の節が空節になるので矛盾です。

![名称未設定のノート-6 4.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/11779/63a372d3-7d63-acc8-83a1-b6c9d11c46a1.jpeg)

このとき得られる原因節$(\lnot V_1 \lor \lnot V_2)$がここでの学習節になります。この矛盾解析の結果$\lnot V_2$が決定レベル$1$に積まれますが、そこからの単位伝搬はなく、そのまま$V_3$が決定されます。すると、単位伝搬によりもう一度矛盾が導かれます。この時の矛盾には$V_3$以外のリテラルが寄与しないので、決定レベル$0$にまでバックジャンプした上で$\lnot V_3$が積まれます。

$\lnot V_3$からの伝搬はないのでそのまま次の決定で$V_1$が選ばれたとします。この時もし学習節があれば$\lnot V_2$が含意されます。そして、その次に$V_4$が決定されれば$\lnot V_5$が伝搬して解が見つかります。これまでのように学習節がない場合は再度$V_2$を決定して矛盾を導くプロセスをやり直すことになってしまいます。

![名称未設定のノート-7.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/11779/ce90fd3c-ef29-b95b-87e5-c38619572a08.jpeg)

さて、ここまでの全ての例ではバックジャンプ後には必ず現在の決定レベルの決定をひっくり返すという想定でした。前節の例でいえば、$\lnot V_3$が積まれる想定です。しかし実は、そこで代わりに$\lnot V_4$を積んでも良いことに気が付きます。というのも、$V_1,V_4$の二つが割り当てられたとしても、やはり同じ矛盾が導かれるからです。

![名称未設定のノート-4.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/11779/c9656268-b742-de4b-8b84-91ed2f2cc937.jpeg)
(前節の例の再掲)

これは、$V_3$も$V_4$もこの含意グラフにおける _Unique Implication Point (UIP)_ だからです。リテラル$L$がUIPであるというのは、$L$が現在の決定レベル$l$のリテラルであって、決定レベルが$l$未満の他のリテラルと合わせると矛盾が導けるうようなときにそう呼びます。例えば$V_4$は$V_1$と合わせればそこから矛盾が導けるのでUIPです。現在の決定レベルの決定リテラルは(矛盾解析が発生したときはいつでも)UIPです。

矛盾解析によって原因節・学習節を獲得する、という定性的な観点から言えば実は獲得する節は UIP であればどれでも良いです。一方定量的な観点からUIP一つを選ぶというのであれば、一番良いのは矛盾に最も近い UIP です。これを _first UIP (1-UIP)_と呼びます。(今、最も矛盾に近い、という表現をしましたが、同じ矛盾から得た UIP はその矛盾からの近さで全順序がつけられることに注意してください。これは絵を描くと明らかです。) というのも、矛盾から近い UIP ほどリテラルの数が少なくなるからです。矛盾から遠い方のUIPは矛盾から近いUIPを(単位伝搬によって)含意するので、論理的には 1-UIP は UIP の中でも一番弱いのですが、リテラルが少ないおかげでこれ以降の探索で単位伝搬に寄与しやすくなります。そこで、アルゴリズムの方も 1-UIP を獲得するように変更することにします。NCBの時は含意グラフを構成できるかだけに注目していましたが、これからは学習節が単位伝搬に有用かどうかを考えなければならなくなったので、選ぶ UIP を変えるというわけです。

さて、これらを実際に実装するためにもう一つ考えなければならないのは学習節の増えすぎです。

これまで動的に生成した原因節はバックトラックのタイミングで削除されていました。しかし、今後はバックトラックが起こっても節は保持したままになります。そうすると矛盾を見つけるたびに節がどんどん増えていってしまい、すぐにシステムのリソースを食いつぶしてしまいます。また、節の数が多すぎると単純にソルバー自体の性能も低下させてしまいます。それを防ぐためには定期的に学習節を削除する必要があります。学習節はあってもなくても問題自体の充足可能性や解の集合を変えるものではないので消してしまっても問題がないのです。

しかし、節の削除のアルゴリズムを具体化するためにはいくつも考慮しなければならない要素があります。少なくとも、以下の3点は明確にしなければなりません。

1. いつ節削除を行うか
2. どの節から削除していくか
3. どれぐらいの数の説を削除するか

残念ながら節の削除については決定版と呼べる方法はなく、基本的にはこれらのパラメータをヒューリスティクスで決めていきます。本記事ではどのようなヒューリスティクスが優れているかについては深入りはせず、実装の枠組みを作ることを目標にします。実際に様々なヒューリスティクスを比較するには多くの実験が必要になるでしょう。

## 実装 (節の学習)

まずは節の学習だけを行う(節の削除はしない)バージョンを作成します。

主な変更点は`analyze()`の中だけですが、`pop()`の方も動的に生成された原因節を`free()`する処理を消すという変更を入れてあります。(コードは省略)

`analyze()`のうち前半、つまり、1-UIPを探す部分は少しの変更だけで実装できます。`count`は含意グラフの中で今現在探索しているリテラルのうち現在のレベルのものの数です。これが一時的に$0$になったタイミングで UIP を見つけたということになります。

```c++
void analyze(clause * conflict) {
    learnt.push_back(0); // reserve learnt[0] for UIP
    uint count = 0; // ココが変わった
    for (uint i = 0; i < conflict->num_lit; ++i) {
        int lit = conflict->lits[i];
        uint v = abs(lit);
        seen[v] = true;
        if (level[v] < decision_level) {
            learnt.push_back(lit);
        } else {
            ++count; // ココが変わった
        }
    }
    int uip;
    for (uint i = trail.size() - 1; true; --i) {
        int lit = trail[i];
        uint v = abs(lit);
        if (! seen[v])
            continue;
        seen[v] = false;
        // ココが変わった
        --count;
        if (count == 0) {
            uip = lit;
            break;
        }
        auto c = reason[v];
        for (uint i = 1; i < c->num_lit; ++i) {
            int lit = c->lits[i];
            uint v = abs(lit);
            if (seen[v])
                continue;
            seen[v] = true;
            if (level[v] < decision_level) {
                learnt.push_back(lit);
            } else {
                ++count; // ココが変わった
            }
        }
    }
    learnt[0] = -uip;
    uint num_lit = learnt.size();
    for (uint i = 1; i < num_lit; ++i)
        seen[abs(learnt[i])] = false;
    // 後半へ
    ...
}
```

1-UIPが求まったら、そこで得た原因節を単位伝搬に利用できるようにします。ここもコード上は本質的には二箇所の変更だけです。特に、最も重要なのが学習節を`watch_clause()`で監視対象にする部分です。(コード中2.) コード上は単に関数を呼んでいるだけなのですが、なぜこれだけで正しく動くのかについてはかなりちゃんと考えないといけません。というのも、2WLでは節の扱いがかなり特殊なため、獲得した節を問題由来の節と同等に扱うためには、節の長さや監視リテラルの選び方についてしっかり考える必要があるのです。

まず、節の長さについてですが、2WLでは長さが1以下の節の扱いが特殊になるのでした。それに対応するため問題由来の節についてはソルバーを回す前に問題を前処理してそのような節を除外したり、先に単位伝搬させるということを行いました。学習節についても同様の扱いが必要で、学習節を追加するときに長さが1の節については監視の対象にしません。(ここはたまたまNCBから何も変更しなくても動いています。)

また、監視リテラルを二つ選ぶ方法についても、果たしてそんなものが選べるのかというところから考える必要があります。結論としては、監視リテラル二つは選べます。

今、獲得した学習節が$(L_1 \lor L_2 \lor \cdots \lor L_n)$だったとして、リテラルが決定レベルで降順に並んでいたとします。このとき、$L_1$と$L_2$をこの節の監視リテラルとして選び、管理リストを更新します。この状態で`analyze()`を終了すると、バックジャンプは$L_2$の決定レベルに対して行われ、$L_1$は一旦未割り当てになったあと真が割り当てられます。この時点で$L_2$から$L_n$は偽になっています。この状態は(I-WL)を満たします。ここからさらにバックジャンプが発生すると$L_1$と$L_2$が未割り当てになるのでやはり(I-WL)を満たします。よって、学習節の中でレベルが最も高い二つのリテラルを監視リテラルとすれば2WLの枠組みとうまく組み合わせられるということがわかります。(コード中1.)

```c++
void analyze(clause * conflict) {
    // 前半から
    ...
    uint max_lv = 0;
    for (uint i = 1; i < num_lit; ++i) {
        uint lv = level[abs(learnt[i])];
        if (lv > max_lv) {
            max_lv = lv;
            swap(learnt[1], learnt[i]); // 1. learnt[1] にバックジャンプ先のレベルのリテラルが入るようにする。
        }
    }
    backjump(max_lv);
    if (num_lit == 1) {
        push(-uip, nullptr);
        learnt.clear();
        return;
    }
    auto c = make_clause(learnt, CLAUSE_LEARNT);
    push(-uip, c);
    learnt.clear();
    watch_clause(c); // 2. 監視を行う
}
```

## 実装 (節の削除; size-based randomization)

解説パートでは節の削除には三つの考えるべきことがあるという話をしました。実装に当たってこれらを先に決めておきます。

1. いつ節削除を行うか
2. どの節から削除していくか
3. どれぐらいの数の説を削除するか

まず、1については決定を行うたびに学習節の数が閾値に達しているか確認し、閾値に達していれば削除を行うこととします。この閾値はこれまで見つかった空節の数に応じて指数で大きくしていくことにします。また、長さが2の学習節は単位伝搬を促進するのに非常に有用だと考えられるので削除しません。2については[Jabbour+ 2014]で提案されているSize-based randomized strategyを採用することにします。この戦略では節ごとに以下で計算されるスコアを割り当てて、よりスコアが大きいものから削除していきます。ただし$k$は事前に設定されたパラメータで、$\omega$はランダムに選ばれます。

$$
\mathrm{score}_k(c) = \begin{cases}
  |c| & (|c| < k) \\\
  |c| + \omega & (\omega \in [0,1))
\end{cases}
$$

3についてはMiniSATに倣って一度に学習節を半分に削減するという戦略を採用します。

以上がこれから実装するものになります。実装上の注意点は、探索中の節削除によって状態が壊れないようにする点です。具体的には、`reason`から参照されている節を削除しないようにしなければなりません。

実際のコードを見ていきます。

まず、全ての節を保持する`db`という`deque`を導入します。最初の`db_num_persistent`個の節は絶対に削除しない節、残りの節は削除しても良い節ということにします。入力由来の節や、長さが2以下の節はpersistent扱いになります。

```c++
deque<clause *> db; // all clauses; first `db_num_persistent` clauses are persistent
uint db_num_persistent;
```

メインループに対する変更は以下の通りです。矛盾を見つけるたびに閾値を更新しつつ、決定を行うたびに`reduce()`を呼んで節の削減を行います。閾値の更新のロジック(追加した6行)はおまじないだらけですがこれはMiniSATのものをそのままクローンしているからです。今回はヒューリスティックの詳細(実験的な結果)には立ち入らないことにしたので、ここはこういうものだと受け入れてください。

```c++
while (1) {
    while (auto conflict = find_conflict()) {
        if (decision_level == 0)
            return false;
        analyze(*conflict);
        // 以下の6行を追加
        ++backoff_timer;
        if (backoff_timer >= backoff_limit) {
            backoff_timer = 0;
            backoff_limit *= 1.5;
            db_limit = db_num_persistent + (db_limit - db_num_persistent) * 1.1;
        }
    }
    if (! decide())
        return true;
    reduce(); // この行を追加
}
```

節を表す構造体に`score`というフィールドを追加しています。`score`が小さいほど節が削除の対象になりにくいです。`flags`は先程言及したもののコードは見せなかったものです。`CLAUSE_LEARNT`に加えて`CLAUSE_LOCK`というビットフラグを追加しています。(用途は後述。)

```c++
enum {
    CLAUSE_LEARNT = 1,
    CLAUSE_LOCK = 2,
};
struct clause {
    uint num_lit;
    int flags;
    double score;
    int lits[];
};
```

`CLAUSE_LOCK`は以下のように変数を割り当てたり割り当てをキャンセルするタイミングで設定されます。

```c++
void push(int lit, clause * c) {
    ...
    reason[var] = c;
    if (c)
        c->flags |= CLAUSE_LOCK;
}
void pop() {
    ...
    clause * c = reason[var];
    if (c)
        c->flags &= ~CLAUSE_LOCK;
}
```

最も重要な`reduce()`関数の実装です。現在`reason`として使用されている節は削除しないようになっています。このせいで正確には節の数を半減することはできないのですが、これでよしとします。

```c++
void reduce() {
    if (db.size() < db_limit)
        return;
    sort(db.begin() + db_num_persistent, db.end(), [](auto x, auto y) {
        return x->score < y->score;
    });
    uint new_size = db_num_persistent + (db.size() - db_num_persistent) / 2;
    for (uint i = new_size; i < db.size(); ++i) {
        if ((db[i]->flags & CLAUSE_LOCK) != 0) {
            db[new_size++] = db[i];
            continue;
        }
        free(db[i]);
    }
    db.resize(new_size);
}
```

最後に学習節のスコアの計算です。計算アルゴリズムは論文のものをそのまま使用しました。今回はパラメータとして論文中で最も良い性能を出したとされる12を選択しました。(このソルバーはまだ大きい問題を解けないのでこのパラメータが今のソルバーにとって良い値かは不明です。)

```c++
#define SBR_BOUND 12

void analyze(clause * conflict) {
    ...
    // learn new clause
    double score;
    if (num_lit < SBR_BOUND) {
        score = num_lit;
    } else {
        score = SBR_BOUND + rand() * (1 / ((double) RAND_MAX + 1));
    }
    auto c = make_clause(learnt, CLAUSE_LEARNT, score);
    if (num_lit == 2) {
        db.push_front(c);
        ++db_num_persistent;
    } else {
        db.push_back(c);
    }
    ...
}
```

# Variable State Independent Decaying Sum

ここまででは単位伝搬やそれに関わる部分の高速化に取り組んできましたが、決定に関わる部分の高速化は行なってきませんでした。つまり、決定の際の変数選択にはまだ改良の余地が残されているということです。現在の`choose()`は単なるループなので、ここを改善することをこの節の目標にします。

```c++
int choose() {
    for (uint v = 1; v <= N; ++v) {
        if (! defined(v))
            return (int) v;
    }
    return 0;
}
```

節削減での話と同様、変数選択も基本的にはヒューリスティクスによるものです。ただし、この部分についてはある種の定石があり、多くのソルバーがそれを実装しています。それが、_Variable State Independent Decaying Sum (VSIDS)_ と呼ばれる手法です。

VSIDSでは各変数にスコアを割り当て、変数選択時にはスコアが最も優れた変数を選びます。その際のスコアとしてVSIDSでは「コンフリクトの解析でその変数が出現した回数」を採用しています。出現回数が多い変数ほどより多くの含意を持ち、それを選択することによって多くのリテラルの値が自動的に決まると考えられるからです。ただし実際に愚直に回数を数えてしまうと桁溢れを起こしてしまうことが想定されるので、定期的に全ての値を定数値で割ります。これによる副作用として、より最近のコンフリクト解析で出現した変数のスコアがより高くなります。(VSIDSといえば普通はこのような解析時の変数の出現回数を数えるアルゴリズムを指すのですが、VSDISの枠組み自体はかなり一般的で何の回数を数えるかはそれなりに自由に選ぶことができます。)

## 実装

まず各変数に対してスコアを保持するようにデータを用意します。コード中では変数のスコアを`activity`と呼んでいます。

```c++
vector<double> activity;
```

スコアの操作には二種類のクエリがあります。一つが、ある変数のスコアを上昇させる操作(`bump_activity()`)、もう一つが全てのスコアを定期的に定数で割る操作(`decay_activity()`)です。
`analyze()`は変数出現を一回見つけるたびに`bump_activity()`を呼び、スコアを`+1`します。ソルバーのメインループである`solve()`は空節が見つかるたびに`decay_activity()`を呼び、定期的に全てのスコアを半減させます。

```c++
void bump_activity(uint v) {
    activity[v] += 1.0;
}
void decay_activity() {
    ++num_conflict;
    if ((num_conflict % ACTIVITY_DECAY_PERIOD) == 0) {
        for (uint v = 1; v <= N; ++v)
            activity[v] *= 0.5;
    }
}
```

例えば、ソルバーのメインループは以下のように変更されます。(コードの見やすさのためにCDCLにまつわるコードを消したものを示しています。)

```c++
while (1) {
    while (auto conflict = find_conflict()) {
        if (decision_level == 0)
            return false;
        analyze(*conflict);
        decay_activity(); // ココ
    }
    if (! decide())
        return true;
}
```

以上でスコアの計算は終わりです。あとは`choose()`をこのスコアに沿って変数を選ぶように変更するだけです。

```c++
int choose() {
    double max_score = 0;
    int max_lit = 0;
    for (uint v = 1; v <= N; ++v) {
        if (! defined(v)) {
            double s = activity[v];
            if (s >= max_score) {
                max_score = s;
                max_lit = (int) v;
            }
        }
    }
    return max_lit;
}
```

## 実装 (ヒープ)

今の実装では`choose()`は単なるループのままでした。変数の集合の中から最もスコアが高い変数を選ぶ、ということをしているので、これをPriority Queueを使って高速化したいと考えるのは自然な発想でしょう。ただし、少し注意する点があります。変数のスコアが`bump_activity()`が呼ばれるたびに変化してしまうという点です。つまり変数のスコアが変わるたびにその変数のPriority Queueの中での位置を再調整できる必要があります。このために、普通の二分ヒープに加えて、変数からその変数の二分ヒープ内での位置を逆引きするための配列を用意します。

```c++
vector<uint> heap; // priority queue for variable selection
vector<uint> heap_index; // variable to index in heap; 0 if variable not in heap
```

ヒープに対する操作(`heap_push()`, `heap_pop()`, `heap_top()`, `heap_up()`など)は普通通りに実装します。(コードは省略) ただし、ヒープの中の値を移動させた場合は`heap_index`の方も変更するようにしておきます。`heap_up()`があれば`bump_activity()`は以下のように実装できます。これで、ヒープの状態と実際のスコアが整合するようになります。

```c++
void bump_activity(uint v) {
    activity[v] += 1.0;
    if (heap_index[v] != 0)
        heap_up(heap_index[v]);
}
```

ヒープの中には未定義の変数が入っていることが期待されるので`push()`では変数をヒープから削除し、`pop()`では変数をヒープに追加することが期待されます。ただし、`push()`の中で変数をヒープから削除するのはコストが大きいので、`push()`で変数をヒープから削除することは諦めてヒープの中に定義済みの変数が入ってしまうことを許容します。その代わりに、`choose()`の中では`heap_pop()`するたびにそれが現在未定義かどうかを確認することにします。

```c++
void pop() {
    ...
    if (heap_index[var] == 0)
        heap_push(var);
}
```

```c++
int choose() {
    while (! heap_empty()) {
        uint v = heap_top();
        heap_pop();
        if (! defined(v)) {
            return v;
        }
    }
    return 0;
}
```

## 実装 (exponential VSIDS / eVSIDS)

VSIDSはそれだけでも十分軽い処理です。しかし、空節が見つかるたびに定期的とはいえ全ての変数を舐める`decay_activity()`はそれなりのコストになります。そこでMiniSATではexponential VSIDS (eVSIDS)と呼ばれるテクニックを用いて`decay_activity()`を高速化しています。

eVSIDSの鍵となる観察は、定期的に全ての変数のスコアを半減させることと、定期的にスコアの上昇度合いを倍増させることが同じであるということです。変数のスコアは優先度としての意味しかなく、相対的な大小にしか意味がありません。今までは`bump_activity()`では必ずスコアを`+1`して`decay_activity()`で定期的に全スコアを半減させていましたが、その代わりに`bump_activity()`でスコアを`+activity_increment`することにして`decay_activity()`で定期的に`activity_increment`を倍にすれば、スコアの大小関係を保ったままで`decay_activity()`の中のループを無くすことができます。ただし、これではスコアが急激に大きくなってしまうので今度は`bump_activity()`の中で定期的にスコアの切り下げを行います。

以上のアイデアを実装したのが以下です。実際のコードでは`ACTIVITY_DECAY_FACTOR`は`0.5`ではなく(MiniSATに倣って)`0.9`にしています。

```c++
void bump_activity(uint v) {
    activity[v] += activity_increment;
    if (activity[v] > ACTIVITY_RESCALE_LIMIT) { // rescore
        activity_increment *= (1 / ACTIVITY_RESCALE_LIMIT);
        for (uint i = 1; i < activity.size(); ++i)
            activity[i] *= (1 / ACTIVITY_RESCALE_LIMIT);
    }
    if (heap_index[v] != 0)
        heap_up(heap_index[v]);
}
void decay_activity() {
    activity_increment *= (1 / ACTIVITY_DECAY_FACTOR);
}
```

# Phase Saving

ここまでのVSIDSに関する節では決定を行う際にどの変数を選択するかを議論してきました。一方で、どの変数を選択するかが決まった時にその変数に真と偽のどちらを割り当てるかについては何も考えてきませんでした。(今のところ常に真を割り当てるようになっています。)実際のところ、どちらを割り当てるのがより効率的なのでしょうか？ 実はこれについてはある程度答えが出ていて、_Phase Saving_ [Pipatsrisawat & Darwiche, 2007] と呼ばれる手法が有効であることが知られています。

Phase saving (あるいはProgress saving, 部分解キャッシュ)の考え方は以下の通りです。

CNF、つまり節集合 $\Delta$ の部分集合 $C \subseteq \Delta$ が $\Delta \setminus C$ と変数を共有しないとき、$C$を$\Delta$の _component_ と呼びます。明らかに、component $C$の解は$\Delta \setminus C$の解には依存しません。
ソルバーの探索中には component の解を探索することが度々発生します。もちろん最初に与えられた問題が複数の component を持つこともあり得ますが、むしろ探索中の特定の時点での(部分)割り当ての下で問題が複数の component に分割できるというような状況の方が支配的でしょう。このような状況では、ソルバーはcomponent $C$とその補集合$\Delta \setminus C$の解を同時に探索することになります。その際、$C$の解は見つかったものの、$\Delta \setminus C$の解の探索中にコンフリクトが見つかる、というようなことが発生します。こうなるとコンフリクト解析を経てバックトラックが行われたときに、すでに見つかっている$C$の解が消えてしまうということが発生します。これを防ごうというのがPhase savingの問題意識です。

ではPhase savingはどのようにしてこれを解決するのかというと、決定をする際に単に前回の割り当て時のphaseを復元するということを行います。もしその変数に一度も割り当てが行われたことがなければ真偽値は適当に選びます。これによってすでに解が見つかっていた component の解をバックトラック後も復元することができ、探索を効率化することができます。

## 実装

Phase savingの実装は非常に簡単で、一行変更するだけです。これまでの実装ではphaseはバックトラックの後も消去されず`model`の中に保存されたままになっているのでそれを取り出すだけです。

```c++
int choose() {
    while (! heap_empty()) {
        uint v = heap_top();
        heap_pop();
        if (! defined(v)) {
            return phase(v) ? (int) v : -(int) v; // 前は `(int) v` だった
        }
    }
    return 0;
}
```

# Restarts

これまでの種々のテクニックの導入の中でいくつかのヒューリスティクスを導入してきました。具体的には節削除と変数選択です。これらの操作はある種の自由度があり、いくつもの選択肢の中からできるだけ最良のものを選ぶべくヒューリスティクスが導入されています。ではもしヒューリスティクスが選んだ選択肢が「ハズレ」だった場合は何が起こるのでしょうか？もっと言えば、どれくらいのペナルティがあるのでしょう、あるいはハズレはどのくらいあるのでしょうか。

このような問いについての研究が [Gomes+, 2000] です。この研究ではDPLLソルバーにランダムな挙動を許した場合にどのような結果になるかを調査したものです。ランダムな挙動を許す、というのはこの場合、例えば「変数選択で$X_1$と$X_2$のどちらも同じぐらいのスコアだった場合にどちらかをランダムに選択する」というような改造を施したという意味です。この論文の結果は非常に示唆的です。例えば論文中の以下の図を見てください。この図はある特定の問題(ここではQuasigroup completion problemというNP完全問題をSATにエンコードしたもの)をソルバーで10000回実行した時に、解を導けた割合をプロットしたものです。横軸はバックトラックの最大回数を何回に設定したかを表しており、バックトラックの数を増やせば増やすほど求解に至る割合が増えています。しかし、この図が示すようにバックトラックの回数をどれだけ大きくしても縦軸が100%になっていません。これはこの問題に限らずあらゆる問題に言えるようで、いずれの場合もこのように裾野が非常に広い分布を示すようです。

![スクリーンショット 2020-12-14 3.53.59.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/11779/a03d3e65-c92b-964c-fe49-71707d936fe5.png)

このように同じソルバーであっても選択肢に自由度がある時に「ハズレ」を引いてしまうと、そうでなければすぐに解けていたはずの問題が解けずじまいになってしまいます。このような事態を防ぐために現代的なソルバーはいずれも _リスタート_ と呼ばれる処理を行います。

リスタートはアイデア自体は非常に簡単で、しばらく探索を続けて答えが分からなければ最初から探索をやり直す、というものです。これをアルゴリズムにする際に考えなければいけないのは

1. 「しばらく」とはどれくらいか
2. 最初から探索をやり直す、とはどういうことか

の2点です。まず二つ目の点については、単に決定レベル0にバックジャンプすることを意味します。この際学習節や変数のスコアは変更しません。このおかげで前回決定レベル0から探索を開始した時とは違うパスが探索されることになります。(節削除や変数選択のヒューリスティクスがあまりに悪いとリスタートの前後で全く同じことになるかもしれませんが普通はまず起こらないと思います。)一つ目の点については _Lubyリスタート_ と呼ばれるやり方を採用します。まず、自然数$k$について以下で定義される自然数列 $(t_i)$ を _Luby数列_ と呼びます。

$$
t_i = \begin{cases}
k2^{j-1} & (\text{$i = 2^j - 1$ for some $j$}) \\\
t_{i - 2^{j-1} + 1} (2^{j - 1} \le i \le 2^j - 1)
\end{cases}
$$

$k=1$の時、この数列は以下のような値になります。

$$
1, 1, 2, 1, 1, 2, 4, 1, 1, 2, 1, 1, 2, 4, 8, \cdots
$$

リスタートはこのLuby数列に従って発火させます。$i$回のリスタート後のソルバーは$t_i$個のコンフリクトを見つけるとその探索を諦めてリスタートを行います。

なぜこのような不思議な数列を使うかというと、これがある意味で最適であることが証明できるからです。[Luby+, 1993] 証明は追っていないのですが、とりあえずこの論文の主張を翻訳すると以下のようになります。

> Aをラスベガスアルゴリズム(必ず停止して答えを出すが、答えに至るまでの時間がランダムであるようなアルゴリズム)とする。
> 戦略$S=(t_0, t_1, \cdots)$を時間の列として、Aを$t_0$ステップ回して、答えがでなければ次に$t_1$ステップ回して…ということを繰り返すとする。
> この時、答えが出るまでの時間の期待値を最小化したい。
> 結論としては、Aの実行ステップ数の分布が不明な場合、戦略$S$としてLuby数列を採用することが任意のAについて最適である。

ここでのAが我々のSATソルバーです。この問題の設定でいうところのアルゴリズムAを1ステップ回すことが、SATソルバーで$k$個のコンフリクトを見つけることに相当します。

## 実装

さて、実装にあたります。ソルバーのメインループが以下のように変更されます。(見やすさのためにVSIDSとdatabase reductionのコードを除去していますが本質は変わりません。)
`restart_timer`が(前回のリスタート以降に)コンフリクトを見つけた数です。先程の説明では$k$個のコンフリクトを見つけ次第リスタートを行う、という説明でしたが、この実装では$k$個のコンフリクトを見つけた後も単位伝搬が一通り終わるまではリスタートをしません。こうすると単位伝搬のループがなかなか終了しない場合にリスタートができず「ハズレ」から抜け出せない気もしますが、それは話が逆で「ハズレ」のケースというのはほとんどが単位伝搬がなかなか起きず枝刈りが全然できない状態であるという経験則があります。そのため単位伝搬が長く続くようであればむしろそれは「ハズレ」を引いていないということだろう、という推測ができます。そのようなケースでは最後まで伝搬を行うことで有用な学習節を得たり解が求まる期待があります。

```c++
while (1) {
    while (auto conflict = find_conflict()) {
        if (decision_level == 0)
            return false;
        analyze(*conflict);
        ++restart_timer; // ココを追加
    }
    if (restart()) // ココを追加
        continue;
    if (! decide())
        return true;
}
```

さて、`restart()`を実装するにあたってLuby数列を実装する必要があります。先程紹介した数式通りに実装するとかなり重い処理になってしまうのですが、幸いビット演算を使った非常に高速な計算方法が知られています。ちなみにこのアルゴリズムを考えたのはDonald Knuthだそうです。(またお前か)

$$
\begin{align}
(u_0, v_0) &= (1, 1) \\\
(u_{i+1}, v_{i+1}) &= \begin{cases}
(u_n + 1, 1) & (\mathrm{bitwiseAND}(u_n, -u_n) = v_n) \\\
(u_n, 2v_n) & (\text{otherwise})
\end{cases}
\end{align}
$$

とすると、$(v_i)$はLuby数列。

ここまでの説明があれば`restart()`関数の実装はすぐ読めます。リスタートの基準を満たしていればLuby数列を計算し、決定レベル0へのバックジャンプを行います。コード中の`RESTART_BASE_INTERVAL`が先程の解説にあった$k$のことです。

```c++
array<int, 2> luby_seq { 1, 1 }; // reluctant doubling

bool restart() {
    if (restart_timer < restart_limit)
        return false;
    luby_seq = {
        (luby_seq[0] & -luby_seq[0]) == luby_seq[1] ? luby_seq[0] + 1 : luby_seq[0],
        (luby_seq[0] & -luby_seq[0]) == luby_seq[1] ? 1 : 2 * luby_seq[1]
    };
    restart_timer = 0;
    restart_limit = RESTART_BASE_INTERVAL * luby_seq[1];
    backjump(0);
    return true;
}
```

# Partial Restarts

さて、先程の実装ではリスタートの際には必ず決定レベル0に戻っていました。決定レベル0に戻った後はその時点での学習節や変数のスコア、保存されたphaseの情報に応じて変数選択と単位伝搬が行われ探索が進みます。しかしもしリスタート後にリスタート前と同じ変数選択が行われた場合、同じような導出を繰り返してしまうことになります。もちろん、学習節の状態が違うので全く同じ単位伝搬が行われるわけではないのですが、リスタート前に行なった伝搬の結果はリスタート後であっても論理的帰結としては正しいままです。また、phase savingにより、決定の際に選ばれるphaseもリスタートの前後で同じものになるはずです。

以上の観測から、リスタートを行うときに必ず決定レベル0にバックジャンプするのではなく、リスタート前とは異なった推論が行われはじめる決定レベルまで巻き戻すのにとどめれば、計算の重複を減らせることがわかります。それが_部分リスタート(Partial restart, Trail reuse)_です。[Ramos+, 2011]

## 実装

アイデアは上で説明した通りなので早速実装してみます。まず、準備として決定レベルからその決定がどのようなものであったか（どのリテラルを選択したか）の情報が辿れるようにするためにグローバルな`vector`を一つ追加します。

```c++
vector<uint> decision; // for parital restarts
```

実際に改造するのは`restart()`関数のみです。先程`backjump(0)`としていた部分が少し複雑なコードに置き換わっています。日本語で処理の内容を説明すると、以下のような処理になっています。

1. リスタート前の状態で次に選ぶことになるであろう変数を得る。(`next_var`)
2. 決定変数をレベル0から順に舐めていき、`next_var`の方がスコアが大きければそこへバックジャンプを行う。

これで通常の決定レベル0に戻るリスタート(フルのリスタートと呼ぶことにします)と同じ効果が得られているかについては少しばかり考えておく必要があります。
そこで、これまでのフルのリスタートで何が起こっていたかを考えてみます。まず大前提として`restart()`は単位伝搬が完了した後にのみ呼ばれます。つまり、その時点での(部分)割り当ては直接は矛盾を導きません。もちろん探索を進めれば矛盾していることがわかるかもしれませんが、そのためには一度は何らかの新たな変数決定を行いそこから空節を導いて新たな節を学習することが必要です。加えて、単位伝搬が完了した後だということは全ての含意リテラルはすでに`trail`に登録されているということを意味しています。よって、リスタート前に割り当てられていた変数をリスタート後にどのような順で再度選択しても、同じ割り当てが復元されるだけです。(phaseも同じになります。) これはそこから単位伝搬を行なっても変わりません。加えて、空節が導かれないので変数のスコアもリスタート前からは変わりません。つまり、リスタート前に未割り当てだった変数のどれかが決定されて初めて探索木の中の新たなパスの探索が始まるということです。しかも、そこで選択される変数はリスタート前の段階で(未割り当ての変数の中で)もっともスコアが高かったものと同じものです。

もう少しこの状況について考えてみます。今がリスタート直後でいくつかの決定を終えているとします。さらに、これまで決定した変数は全てリスタート前に割り当て済みだったものだとします。先程説明した理由からこの時点での割り当てはどう頑張ってもリスタート前の割り当ての部分集合にしかなっていません。ただし、どの変数が決定変数でどの変数が含意変数かについてはリスタートの前後で変わっている可能性があります。よって、どのタイミングで初めてリスタート前に未割り当てだった変数が決定されるかは、リスタート前に割り当て済みだった決定変数と含意変数のうちどの変数がリスタート後の決定変数として選ばれたかに依存します。

この意味で、以下で実装した部分リスタートはフルのリスタートよりもアグレッシブなリスタートを行います。どういうことかというと、リスタート後に`next_var`が決定されるより前のタイミングでは、フルのリスタートであればリスタート前に含意変数だったものが決定変数として選択される可能性がありますが、部分リスタートではリスタート前に決定変数だったものしか決定変数になりえず、しかも決定変数内の順番の入れ替わりもありません。結果的に`next_var`より前に割り当てられる変数の数(つまりリスタートの前後で引き継ぐ知識の量)はフルのリスタートよりも部分リスタートの方が同じか少なくなるため、部分リスタートの方が未探索の領域を探索しやすいことになります。

```c++
bool restart() {
    if (restart_timer < restart_limit)
        return false;
    luby_seq = {
        (luby_seq[0] & -luby_seq[0]) == luby_seq[1] ? luby_seq[0] + 1 : luby_seq[0],
        (luby_seq[0] & -luby_seq[0]) == luby_seq[1] ? 1 : 2 * luby_seq[1]
    };
    restart_timer = 0;
    restart_limit = RESTART_BASE_INTERVAL * luby_seq[1];

    // 以下のコードを追加
    uint next_var;
    while (1) {
        if (heap_empty())
            return false;
        next_var = heap_top();
        if (! defined(next_var))
            break;
        heap_pop();
    }
    auto next_activity = activity[next_var];
    for (uint level = 0; level < decision_level; ++level) {
        uint var = decision[level + 1];
        if (activity[var] < next_activity) {
            backjump(level);
            return true;
        }
    }
    return false;
}
```

# その他の最適化

ここまで様々な最適化を施してきましたが、これでもまだMiniSATには遠く及ばない程度の性能です。小さなインスタンスならしばしば勝つことがある、ぐらいです。

本当はここで解説を終わらせるつもりだったのですが、ソルバーをいじっているうちに勝ちたくなってきたので、ここまでのソルバーの上にさらに以下を実装しました。

1. conflict clause minimization (ccmin)
2. in-process simplification
3. literal block distance (LBD)

1はCDCLに関連するものです。学習節はしばしば不要なリテラルを含むことがあります。不要というのは、ここでは他のリテラルからの単位伝搬によって割り当てが(偽に)決まるという意味です。conflict clause minimizationは`analyze()`のなかで学習節を`db`に登録する前に節から不要なリテラルを取り除く処理のことを指します。

ccminのアルゴリズムには松と竹があって、竹の場合は動作が軽量ですが削除するリテラルの量が少ないです。一方松の場合は処理が重くなりますがその分リテラルを多く削除できます。今回は両方実装しました。

2は探索中に問題そのものの単純化を行うというものです。この処理は決定レベルが$0$の割り当てが積まれた時におこないます。通常simplificationというとCNFを充足可能性を保ったまま別のCNFに書き換える操作のことで、非常に重い可能性があるが、その分CNFを大きく単純化できる操作を指します。通常はソルバーの実行前に一回動作させます。(preprocessing) simplificationは重い操作なので探索中に頻繁に回すことはできないのですが、決定レベルが$0$の割り当てが増えた時にはその割り当てが巻き戻されることがないため、多少重い操作でも問題が簡単になるメリットの方が大きいことが多いです。今回は充足済みの節の削除と、偽なリテラルの削除を実装しました。

3は今回最も効いた変更です。LBDは節の長さの一般化のようなもので、全てのリテラルが割り当て済みの節に対して定義される値です。その定義はというと、節の中のリテラルをそれが割り当てられた決定レベルでクラスタリングし、そのクラスタの数をLBDと呼ぶ、というものです。特にLBDが2の学習節は長さが非常に長くても単位伝搬を促進する可能性が高いです。LBDを節のスコアとして節の削除を行うことで、有用な節が残りやすくなります。

この三つを実装したところ、大抵のケースでMiniSATに勝てるようになりました :tada: ただし、これは MiniSAT のプリプロセスをオフにした場合の話で、これをオンにすると余裕で負けます。(相当難しい問題なら勝てるかもしれない) MiniSATに堂々と勝ったと宣言できるためにはプリプロセスも実装しないといけません。

この三つについては具体的なコードの解説はここではしませんが、リポジトリにはそれぞれの実装がちゃんと上がっています。ここに書いた動機を理解した上でコードを読めばすぐに理解できると思うのですが、ccmin(松)だけはちょっとややこしいです。

# まとめ

ここまでで高速SATソルバーを実装するのに必要なテクニックを学んできました。記事冒頭で紹介した節の依存関係の絵をもう一度みてみましょう。大体概観がつかめたでしょうか？

![名称未設定のノート-8.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/11779/e73dfab1-e328-13a3-e7af-56ddcd5f07bd.jpeg)

SATソルバーのテクニックを解説した文章はいくつもネット上に転がっていますが、本記事のように、

1. 動くコードと一緒に見ながら
2. ここ数年で誕生した新しいテクニックも網羅しつつ
3. コードがなぜ動くのかを徹底的に解説した

記事はそうないのではないでしょうか？というよりも、無いのが不満だったのでこの記事を書いたという動機があるので、この記事が上の三つを達成できていれば本望です。特に3については正直「ここまでコードのインバリアントや最適化が有用になる具体例について丁寧に文章で書き下したものは世の中に存在しないんじゃないか」と思うぐらいかなり丁寧に説明したつもりです。(締め切り駆動特有のハイテンションな結びの言葉) 

特に2WLのインバリアントについてはとても力を入れました。原論文[Moskewicz+, 2001]を含めてかなり幅広く論文や講義資料を漁ったのですが、2WLがなぜ動くかをちゃんと本記事ほど丁寧に書いている文章を見つけられませんでした。(英語・日本語どちらも見当たりませんでした。) Coqで2WLの形式化を行なっている[Fleury+, 2018]はかなり欲しいものに近かったのですが、すでに動いているアルゴリズムに対してインバリアントを天下り的に与えている(それが理由か本記事で議論したインバリアントとは違うインバリアントを採用している)のが微妙だったので、本記事では違う方針を取りました。そのおかげというかそのせいで形式的な議論に慣れていない人には少し追いづらかったかもしれません。(自分がハッピーなのでOKの精神。)

他にも、NCBについての記述は本記事特有だと思います。実は、NCBを単体で実装しているソルバーというのはかなり調べても全然見つかりません。(もしかしたら世の中にないものを生み出してしまったのかもしれない。) 見つけた範囲では全ての実装がNCBとCDCLを同時に実装していました。例えば、[Ketabi+, 2011]では今回説明したような個別の最適化技法がそれぞれどのくらいソルバーの性能を向上させているかを測っているのですが、ここでもCDCLとNCBは両方有効にするか両方無効にするかの二択になっています。(これについては[Nadel&Ryvchin, 2018]でも同じことが指摘されています。) [Lynce & Marques-Silva, 2002]には

> It would be interesting to distinguish between results obtained with non-chronological backtracking and with clause recording, since these techniques do not necessarily have to be jointly applied.

という注釈があり、当初からCDCLとNCBはあまり分離して考えられてはいなかったようです。ただし、最近は無条件にNCBを行うのは弊害が大きいという話も出ており[Nadel&Ryvchin, 2018]、近年見直しが進んでいるところのようです。

また、本記事(というかリポジトリ)のように各実装技術がお互いに干渉しないように注意深く実装されているものも世の中にほとんど無いと思います。実のところ、この記事のために2週間ぐらいひたすらソルバーのコードの歴史修正を繰り返していて、何回も心が折れそうになったのですが、おかげでコミットの差分がとてもわかりやすくなったと思います。歴史修正を繰り返しまくった結果、実はベースラインの実装が当初と比べてめちゃくちゃ速くなってしまい、それに合わせて記事を書き直す…というサイクルが発生してしまっていたのもつらいポイントの一つだったのですが、実装上の高速化とアルゴリズムそのものに起因する高速化を切り分けられたのは結果的にはよかったなと思います。とにかく歴史修正が大変だったので、ぜひgithubにその成果を見に行ってください。URLはこちら → https://github.com/nyuichi/yabai-sat.git

さて、言及するのがめちゃくちゃ遅くなってしまいましたが、なんとこの記事は高速化の記事であるにもかかわらずベンチマークが一つも載っていません。もちろん当初の予定では各節にベンチマークの結果を載せるつもりだったのですが、実際のところまるで間に合いませんでした。すいません。マイクロベンチマークの結果はあるはあるのですがデータとしてまとめるには非常に不便です。というのも、この記事の実装を通してSATソルバーが高速化されすぎていて、一番最初の実装と一番最後の実装でまともな時間で解ける問題のサイズがあまりに変わっているのです。加えて、SATの問題というのは色々な特性があり、さまざまな問題を解いてみてやっと全体の性能がわかるというのがあります。今回の実装範囲でまともな時間で動くさまざまな問題セットを集める、というのがなかなか難しく、色々後回しにしていたら締め切りになってしまいました。いつかそのうちちゃんと計測したいと思います。

この種の記事では最後の方に参考文献がまとまっているのが普通です。今回もソルバーを作るに当たって結構な数の論文を読んだんですが、残念ながら締め切りがやばすぎてあまりまとめきれませんでした。本当に重要なものについては略式ですが参照を文中に載せたので活用してみてください。

ちなみに、実装に当たって参考にしたコードは以下の通りです。

- li-sat-solver https://github.com/necavit/li-sat-solver/ ソルバーを作り始めた時に参考にしたやつ。コードが綺麗。機能は少ない。
- MiniSAT https://github.com/niklasso/minisat コードはあまり綺麗じゃない(個人の感想)ですが、アルゴリズムが参考になります。
- Glucose https://github.com/mi-ki/glucose-syrup (非公式ミラー?) あまりみてないですが LBD の実装の確認とかに使いました。

あとこの節を書いてる途中に見つけた Rust のSATソルバーが割と良さそうだったので紹介しておきます。精読はしてません。

- https://github.com/shnarazk/splr

そろそろ書きたいこともなくなってきたのでこの辺りで記事を締めたいと思います。この記事をきっかけにSATソルバーを作ろうと思った方がいれば光栄です。この文章を読めば少なくともMiniSATをちぎるソルバーぐらいなら簡単に書けると思います。あるいはこの記事がすでにSATソルバーを作っている人にとって良い刺激になったり、より深い理解につながれば幸いです。多分そういう人は自分と感性が似ていると思うので今度飲みにいきましょう。それでは。
